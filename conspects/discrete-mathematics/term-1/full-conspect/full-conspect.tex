\documentclass[12pt]{article}

% Автор стиля: Сергей Копелиович
% Автор конспекта: Илья Дудников

\usepackage{cmap}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{amsthm,amsmath,amssymb}
\usepackage{listings}
\usepackage{color}
\usepackage{xcolor}
\usepackage{array}
\usepackage{mathrsfs}
\usepackage{import}
\usepackage{epigraph}
\usepackage{caption}
\usepackage{subcaption}

\usepackage[russian,colorlinks=true,urlcolor=red,linkcolor=blue]{hyperref}
\usepackage{enumerate}
\usepackage{datetime}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{verbatim}
\usepackage{tikz}
\usetikzlibrary{arrows,decorations.markings,decorations.pathmorphing}
\usepackage{pgfplots}

\usepackage{ifthen}
\usepackage{mathtools}

%\usepackage{tabls}
%\usepackage{tabularx}
%\usepackage{xifthen}
%\listfiles

\def\NAME{Лекции}

\input code-format.tex

\sloppy
\voffset=-20mm
\textheight=235mm
\hoffset=-22mm
\textwidth=180mm
\headsep=12pt
\footskip=20pt

\DeclareMathOperator{\sort}{sort}
\DeclareMathOperator{\const}{const}

\parskip=0em
\parindent=0em

\setlength\epigraphwidth{.8\textwidth}

\newlength{\tmplen}
\newlength{\tmpwidth}
\newcounter{listcounter}

% Список с маленькими отступами
\newenvironment{MyList}[1][4pt]{
  \begin{enumerate}[1.]
  \setlength{\parskip}{0pt}
  \setlength{\itemsep}{#1}
}{       
  \end{enumerate}
}
% Вложенный список с маленькими отступами
\newenvironment{InnerMyList}[1][0pt]{
  \vspace*{-0.5em}
  \begin{enumerate}[(a)]
  \setlength{\parskip}{-0pt}
  \setlength{\itemsep}{#1}
}{       
  \end{enumerate}
  \vspace*{-0.5em}
}
% Список с маленькими отступами
\newenvironment{MyItemize}[1][4pt]{
  \begin{itemize}
  \setlength{\parskip}{0pt}
  \setlength{\itemsep}{#1}
}{       
  \end{itemize}
}

% Основные математические символы
\def\TODO{{\color{red}\bf TODO}}
\def\E{\mathbb{E}}
\def\D{\mathbb{D}}
\def\N{\mathbb{N}}       %
\def\R{\mathbb{R}}       %
\def\F2{\mathbb{F}_2}    %
\def\Z{\mathbb{Z}}       %
\def\INF{\t{+}\infty}    % +inf
\def\EPS{\varepsilon}    %
\def\EMPTY{\varnothing}  %
\def\PHI{\varphi}        %
\def\SO{\Rightarrow}     % =>
\def\EQ{\Leftrightarrow} % <=>
\def\t{\texttt}          % mono font
\def\c#1{{\rm\sc{#1}}}   % font for classes NP, SAT, etc
\def\O{\mathcal{O}}      %
\def\NO{\t{\#}}          % #
\def\XOR{\text{ {\raisebox{-2pt}{\ensuremath{\Hat{}}}} }}
\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}
\newcommand{\q}[1]{\langle #1 \rangle}               % <x>
\newcommand\URL[1]{{\footnotesize{\url{#1}}}}        %
% \newcommand{\sfrac}[2]{{\scriptscriptstyle\frac{#1}{#2}}}  % Очень маленькая дробь
% \newcommand{\mfrac}[2]{{\scriptstyle\frac{#1}{#2}}}    % Небольшая дробь
\newcommand{\sfrac}[2]{{\scriptstyle\frac{#1}{#2}}}  % Очень маленькая дробь
\newcommand{\mfrac}[2]{{\textstyle\frac{#1}{#2}}}    % Небольшая дробь

\newcommand{\fix}[1]{{\color{fixcolor}{#1}}} % \underline
\def\bonus{\t{\red{(*)}}}
\def\ifbonus#1{\ifthenelse{\equal{#1}{}}{}{\bonus}}
\def\smallsquare{$\scalebox{0.5}{$\square$}$}

\newlength{\myItemLength}
\setlength{\myItemLength}{0.3em}
\def\ItemSymbol{\smallsquare}
\def\Item{\vspace*{\myItemLength}\ItemSymbol \ \ }

\newcommand{\LET}{%
  % [line width=0.6pt]
  \begin{tikzpicture}%
  \draw(0.8ex,0) -- (0.8ex,1.6ex);%
  \draw(0,1.6ex) -- (0.8ex,1.6ex);%
  \end{tikzpicture}%
  \hspace*{0.1em}%
}

% Отступы
\def\makeparindent{\hspace*{\parindent}\unskip}
\def\up{\vspace*{-0.5em}}%{\vspace*{-\baselineskip}}
\def\down{\vspace*{0.5em}}
\def\LINE{\vspace*{-1em}\noindent \underline{\hbox to 1\textwidth{{ } \hfil{ } \hfil{ } }}}
\def\BOX#1{\mbox{\fbox{\bf{#1}}}}
\def\Pagebreak{\pagebreak\vspace*{-1.5em}}

% Мелкий заголовок
\newcommand{\THEE}[1]{
  \vspace*{0.5em}
  \noindent{\bf \underline{#1}}%\hspace{0.5em}
  \vspace*{0.2em}
}
% Другой тип мелкого заголовка
\newcommand{\THE}[1]{
  \vspace*{0.5em} $\bullet$
  \noindent{\bf #1}%\hspace{0.5em}
  \vspace*{0.2em}
}

\newenvironment{MyTabbing}{
  \t\bgroup
  \vspace*{-\baselineskip}
  \begin{tabbing}
    aaaa\=aaaa\=aaaa\=aaaa\=aaaa\=aaaa\kill
}{
  \end{tabbing}
  \t\egroup
}

% Код с правильными отступами
\lstnewenvironment{code}{
  \lstset{}
%  \vspace*{-0.2em}
}%
{
%  \vspace*{-0.2em}
}
\lstnewenvironment{codep}{
  \lstset{language=python}
}%
{
}

% Формулы с правильными отступами
\newenvironment{smallformula}{
 
  \vspace*{-0.8em}
}{
  \vspace*{-1.2em}
  
}
\newenvironment{formula}{
 
  \vspace*{-0.4em}
}{
  \vspace*{-0.6em}
  
}

% Большая квадратная скобка
\makeatletter
\newenvironment{sqcases}{%
  \matrix@check\sqcases\env@sqcases
}{%
  \endarray\right.%
}
\def\env@sqcases{%
  \let\@ifnextchar\new@ifnextchar
  \left\lbrack
  \def\arraystretch{1.2}%
  \array{@{}l@{\quad}l@{}}%
}
\makeatother

% Определяем основные секции: \begin{Lm}, \begin{Thm}, \begin{Def}, \begin{Rem}
\renewcommand{\qedsymbol}{$\blacksquare$}
\theoremstyle{definition} % жирный заголовок, плоский текст
\newtheorem{Solution}{Решение}
\newtheorem{Thm}{\underline{Теорема}}[subsection] % нумерация будет "<номер subsection>.<номер теоремы>"
\newtheorem{Lm}[Thm]{\underline{Lm}} % Нумерация такая же, как и у теорем
\newtheorem{Ex}[Thm]{Упражнение} % Нумерация такая же, как и у теорем
\newtheorem{Example}[Thm]{Пример} % Нумерация такая же, как и у теорем
\newtheorem{Code}[Thm]{Код} % Нумерация такая же, как и у теорем
\theoremstyle{plain} % жирный заголовок, курсивный текст
\newtheorem{Def}[Thm]{Def.} % Нумерация такая же, как и у теорем
\theoremstyle{remark} % курсивный заголовок, плоский текст
\newtheorem{Cons}[Thm]{Следствие} % Нумерация такая же, как и у теорем
\newtheorem{Conj}[Thm]{Гипотеза} % Нумерация такая же, как и у теорем
\newtheorem{Prop}[Thm]{Утверждение} % Нумерация такая же, как и у теорем
\newtheorem{Rem}[Thm]{Замечание} % Нумерация такая же, как и у теорем
\newtheorem{Remark}[Thm]{Замечание} % Нумерация такая же, как и у теорем
\newtheorem{Algo}[Thm]{Алгоритм} % Нумерация такая же, как и у теорем

% Определяем ЗАГОЛОВКИ
\def\SectionName{Дискретная математика}
\def\AuthorName{Илья Дудников}
\def\SEASON{Конспект лекций по дискретной математике, ПИ, 1 семестр}

\newlength{\sectionvskip}
\setlength{\sectionvskip}{0.5em}
\newcommand{\Section}[4][]{
  % Заголовок
  \pagebreak
%  \ifthenelse{\isempty{#1}}{
    \refstepcounter{section}
%  }{}
  \vspace{0.5em}
%  \ifthenelse{\isempty{#1}}{
%    \addtocontents{toc}{\protect\addvspace{-5pt}}%
    \addcontentsline{toc}{section}{\arabic{section}. #2}
%  }{}
  \begin{center}
    {\Large \bf Раздел \NO{\arabic{section}}: #2} \\ 
    \vspace{\sectionvskip}
    \ifthenelse{\equal{#3}{}}{}{{\large #3}\\}
  \end{center}

  \LINE

  % Запомнили название и автора главы
  \gdef\SectionName{#2}
  \gdef\AuthorName{#4}

  % Заголовок страницы
  \lhead{\SEASON}
  \chead{}
  \rhead{\SectionName}
  \renewcommand{\headrulewidth}{0.4pt}

  \lfoot{Глава \NO{\arabic{section}}.}
  \cfoot{\thepage\t{/}\pageref*{LastPage}}
  \rfoot{Автор: \AuthorName}
  \renewcommand{\footrulewidth}{0.4pt}
}

\newcommand{\Subsection}[2][]{
  \refstepcounter{subsection}
  \vspace*{1em}
  \ifthenelse{\equal{#1}{}}
    {\addcontentsline{toc}{subsection}{\arabic{section}.\arabic{subsection}. #2}}
    {\addcontentsline{toc}{subsection}{\arabic{section}.\arabic{subsection}. \bonus\,#2}}
  {\color{blue}\bf\large \arabic{section}.\arabic{subsection}. \ifbonus{#1}\,{#2}} 
  \vspace*{0.5em}
  \makeparindent
}
\newcommand{\Subsubsection}[2][]{
  \refstepcounter{subsubsection}
  \vspace*{1em}
  \ifthenelse{\equal{#1}{}}
    {\addcontentsline{toc}{subsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}. #2}}
    {\addcontentsline{toc}{subsubsection}{\arabic{section}.\arabic{subsection}.\arabic{subsubsection}. \bonus\,#2}}
  {\color{blue}\bf\large \arabic{section}.\arabic{subsection}.\arabic{subsubsection}. \ifbonus{#1}\,#2}
  \vspace*{0.5em}
  \makeparindent
}

\newcommand{\Header}{
  \pagestyle{empty}
  \renewcommand{\dateseparator}{--}
  \begin{center}
    {\Large\bf 
     Дискретная математика 1 семестр ПИ,\\
    \vspace{0.3em}
     \NAME}\\
    \vspace{0.7em}
    {Собрано {\today} в {\currenttime}}
  \end{center}

  \LINE
  \vspace{0em}

  \renewcommand{\baselinestretch}{0.98}\normalsize
  \tableofcontents
  \renewcommand{\baselinestretch}{1.0}\normalsize
  \pagebreak
}

\newcommand{\BeginConspect}{
  \pagestyle{fancy}
  \setcounter{page}{1}
}

\definecolor{mygray}{rgb}{0.7,0.7,0.7}
\definecolor{ltgray}{rgb}{0.9,0.9,0.9}
\definecolor{fixcolor}{rgb}{0.7,0,0}
\definecolor{red2}{rgb}{0.7,0,0}
\definecolor{dkred}{rgb}{0.4,0,0}
\definecolor{dkblue}{rgb}{0,0,0.6}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{brown}{rgb}{0.5,0.5,0}

\newcommand{\green}[1]{{\color{green}{#1}}}
\newcommand{\black}[1]{{\color{black}{#1}}}
\newcommand{\red}[1]{{\color{red}{#1}}}
\newcommand{\dkred}[1]{{\color{dkred}{#1}}}
\newcommand{\blue}[1]{{\color{blue}{#1}}}
\newcommand{\dkgreen}[1]{{\color{dkgreen}{#1}}}

\DeclareMathOperator{\cov}{cov} 
\DeclareMathOperator{\sign}{sign} 

\begin{document}

\Header

\BeginConspect

\Section{Основы комбинаторики}{}{Илья Дудников}

\Subsection{Множества}

\begin{Def}
    Множество - совокупность объектов.
\end{Def}

\begin{Def}
    Покрытием множества $A$ называется множество $B = \left\{B_1, B_2, ..., B_k\right\} : \bigcup_i B_i \supset A$ 
\end{Def}

\begin{Def}
    Разбиением множества $A$ называется $\pi (X) = \{X_i\} : $
    \[X_i \neq \varnothing, \bigcup_i X_i = A, \forall i \neq j \to X_i \cap X_j = \varnothing\] 
\end{Def}

\begin{Def}
    Пусть $B, C$ -- разбиения $A$. $B$ называется измельчением $C$, если $B$ -- разбиение $A$ и $\forall i \ \exists j : B_i \subset C_j$   
\end{Def}

\Subsection{Мощность множества}

\begin{MyList}
    \item $|\varnothing| = 0$ 
    \item $X = \left\{x_1, x_2, ..., x_n\right\} \SO |X| = n$ 
    \item $\N$ -- счётное. $\Z$ -- тоже счётное:
    \[f(x) = \begin{cases}
        1, x = 0 \\
        2x, x > 0 \\
        2|x| + 1, x < 0
    \end{cases}\]
    \item $[0, 1]$. Пусть существует $q: \N \to [0, 1]$
    
    \begin{MyList}
        \item $0, a_1 a_2 ... a_k ...$
        \item $0, b_1 b_2 ... b_k ...$ 
        \item $0, c_1 c_2 ... c_k ...$  
    \end{MyList}
    Рассмотрим $\alpha = 0, \alpha_1 \alpha_2 \alpha_3 ... \alpha_k ..., \alpha_1 \neq a_1, \alpha_2 \neq b_2, \alpha_3 \neq c_3$ и т.д. 
    Таким образом, всегда найдётся не пронумерованное число. 

    $|[0, 1]|$ -- континуум 
\end{MyList}

\begin{Def}
    Множество всех подмножеств $A$ обозначается $2^A$ 
\end{Def}

\begin{Prop}
    $|2^A| = 2^{|A|}$  
\end{Prop}

\begin{proof}
    База: $A = \varnothing, |A| = 0, 2^A = \{\varnothing\} \SO |2^A| = 2^{|A|} = 1$
    
    Индукционное предположение: Пусть $\forall A : |A| \leqslant k \to |2^A| = 2^{|A|}$ \\
    Индукционный переход:

    Рассмотрим $A : |A| = k + 1, B_1 \in 2^{A \setminus \{x_{k + 1}\}}, B = \{x_{k + 1}\} \cup B_1$ 

    $2^A = 2^{A \setminus \{x_{k + 1}\}} \cup \{B\}$ 

    \[\begin{cases}
        |2^{A \setminus \{x_{k + 1}\}}| = 2^k \\
        |\{B\}| = 2^k
    \end{cases} \SO 2^A = 2^k + 2^k = 2^{k + 1} = 2^{|A|}\]
\end{proof}

\Pagebreak
\Subsection{Комбинаторика}

\begin{MyList}
    \item $A, B : A \cap B = \varnothing$ $$|A \cup B| = |A| + |B|$$
    \item $A_1, ..., A_n, \forall i, j \to (i \neq j \SO A_i \cap A_j = \varnothing)$
    \[|\bigcup_{i = 1}^n A_i| = \sum_{i=1}^{n} |A_i|\]
    \item $A, B, A \cap B \neq \varnothing$ \[|A \cup B| = |A| + |B| - |A \cap B|\] 
    \item $A_1, ..., A_n$ \[|\bigcup_{i = 1}^n A_i| = \sum_{i=1}^{n} |A_i| - \sum_{i, j=1}^{n} |A_i \cap A_j| + \sum_{i,j,k=1}^{n} |A_i \cap A_j \cap A_k - ... + (-1)^{n + 1}|\bigcap_{i = 1}^n A_i|\]
    \item $A, B$ \[|A \times B| = |A| \cdot |B|\]
    \item $A_1, ..., A_n$ \[|A_1 \times A_2 \times ... \times A_n| = \prod_{i = 1}^n |A_i|\]   
\end{MyList}

\begin{MyList}
    \item Перестановки: $\langle a_1 ... a_n\rangle = \overline{\langle a_1 ... a_n\rangle, a_n}$. Тогда
    \[|\langle 1:n\rangle| = |\langle 1:n - 1\rangle \times (1:n)| = |\langle 1:n - 1\rangle| \cdot n = 1 \cdot 2 \cdot ... \cdot n = n!\]

    \item Размещения. $n \cdot (n - 1) \cdot ... \cdot (n - k + 1)$
    \[A_n^k = \frac{n!}{(n - k)!}\]

    \item Сочетания. 
    \[A_n^k = C_n^k \cdot k! \EQ C_n^k = \frac{n!}{k!(n - k)!}\]

    \item Сочетания с повторениями. Выставим все $k$ выбранных объектов в ряд и поставим между ними $n - 1$ перегородку: до первой перегородки будут элементы 1-го типа, от первой до второй перегородки -- 2-го типа и т.д.
    Таким образом, всего $n + k - 1$ место. Нам нужно выбрать $n - 1$ перегородку из этих $n + k - 1$ мест
    \[\overline{C}_n^k = C_{n + k - 1}^{n - 1} = C_{n + k - 1}^k\]
\end{MyList}

\begin{Def}
Пусть дан выпуклый $n$-угольник. Найти количество способов разбить его на треугольники с непересекающимися сторонами

\[C_0 = 1, C_n = \sum_{i=0}^{n - 1} C_i \cdot C_{n - i - 1} - \text{ Числа Каталана}\]

\end{Def}

\Section{Перестановки}{}{Илья Дудников}

\Subsection{Лексикографический порядок перестановок}

\begin{Def}
    Пусть есть две перестановки $X = \{x_1, x_2, ..., x_n\}, Y = \{y_1, y_2, ..., y_n\}$. Тогда 
    \[X < Y \EQ \exists k : x_i = y_i \ \forall i = 1, ..., k \wedge x_{k + 1} < y_{k + 1}\]   
\end{Def}

\begin{Algo}[Поиск следующей перестановки]
    Найдем наибольший убывающий суффикс. 
    Пусть $k : a_{k + 1} > a_{k + 2} > ... > a_n$. Тогда выберем из этого суффикса $a_i : a_i > a_k$ и $a_i$ минимально.
    После этого отсортируем получившийся суффикс. Получим перестановку:
    \[\langle a_1, a_2, ..., a_i, \sort [a_k, a_k + 1, ..., a_n]\rangle\]
    Она и будет лексикографический следующей.
\end{Algo}

\Section{Числа Стирлинга}{}{Илья Дудников}

\Subsection{Числа Стирлинга}
\begin{Def}
    Пусть $A = \{a_1, ..., a_n\}$. Рассмотрим разбиение этого множества мощности $k$, т.е. $X = \{X_1, ..., X_k\}:$
    $$\forall i, j \to X_i \supset A, X_i \cap X_j = \varnothing, \bigcup_i X_i = A$$
    
    Тогда числами Стирлинга -- количество таких разбиений.
\end{Def}

\begin{MyList}
    \item $k = 2 \SO S(n, 2) = \frac{\sum_{i=1}^{n - 1} C_n^i}{2} = \frac{2^n - 2}{2} = 2^{n - 1} - 1$
    \item Общий случай.
    \begin{MyItemize}
        \item Если $\{a_n\}$ -- элемент разбиения, то таких разбиений $S(n - 1, k - 1)$
        \item $\exists i : a_n \in X_i, |X_i| > 1$. Тогда нужно найти количество разбиений $A \setminus \{a_n\}$ на $k$ множеств, а потом вставить $a_n$ в одно из этих множеств.
        
        Количество способов:
        \[S(n - 1, k) \cdot k\]
    \end{MyItemize}

    Тогда рекуррентная формула:
    \[S(n, k) = S(n - 1, k - 1) + S(n - 1, k) \cdot k\]
    Базовые значения:
    \[
    \begin{array}{cc}
    S(n, 0) = 0 & S(0, 0) = 0 \\ 
    S(k, n) = 0, k > n & S(n, 2) = 2^{n - 1} - 1 \\ 
    S(n, n - 1) = C_n^2 & 
    \end{array} 
    \]
\end{MyList}

\Subsection{Числа Белла}
\begin{Def}
    Числа Белла -- количество разбиений множества.
    \[B(n) = \sum_{i=1}^{n} S(n, i)\]
\end{Def}

\begin{Thm}[Формула чисел Белла]
    Рассмотрим произвольное разбиение множества $A$. $\exists i : a_{n + 1} \in X_i, |X_i| = j$.
    
    $|A \setminus X_i| = n + 1 - j$. Тогда количество способов выбрать $X_i$ равно $C_n^{j - 1} = C_n^{n + 1 - j}$
    
    Количество разбиений $A \setminus X_i$, в свою очередь, равно $B(n + 1 - j)$. Тогда 
    \[B(n + 1) = \sum_{j=1}^{n + 1} C_n^{n + 1 - j} \cdot B(n + 1 - j) = \sum_{k=0}^{n} C_n^k B(k)\]  
\end{Thm}

\Pagebreak
\begin{Thm}[Формула чисел Стирлинга]
    \[S(n, k) = \frac{1}{k!} \sum_{j=0}^{k} (-1)^j \cdot C_k^j (k - j)^n\]    
\end{Thm}

\begin{proof}
    Пусть $L = \{\rho \subseteq A \times \{1, ..., k\} | \rho \text{ -- сюръекция}\}$. Заметим, это множество равномощно множеству упорядоченных разбиений мощности $k$. \\
    $\{a_1, ..., a_n\} \to \{1, ..., k\}$. Элементы разбиения имеют следующий вид: $X_i = \{a_k | \rho(a_k) = i\}$. Т.к. отображение сюръективно, то $X_i$ непусты.
    \[S(n, k) = \frac{|L|}{k!}\]
    Чтобы посчитать мощность $L$, из общего количества отображения вычтем количество несюръективных отображений.
    Пусть $P_i = \{\rho \subset A \times \{1, ..., n\} | \forall a \in A \to \rho(a) \neq i\}$. Тогда количество несюръективных отображений равно:
    \[|\bigcup_{i = 1}^k P_i| = \sum_{j=1}^{k} (-1)^{j + 1} \sum_{1 \leqslant i_1 \leqslant i_2 \leqslant i_3 \leqslant ... \leqslant i_j \leqslant k} |P_{i_1} \cap P_{i_2} \cap ... \cap P_{i_j}|\]
    $|P_{i_1} \cap P_{i_2} \cap ... P_{i_j}|$ -- количество отображений из $A$ в $\{1, ..., k\} \setminus \{i_1, ..., i_j\}$ 
    \[|P_{i_1} \cap ... \cap P_{i_j}| = (k - j)^n\]
    \[\sum_{i_1 \leqslant i_2 \leqslant ... \leqslant i_j} |P_{i_1} \cap P_{i_2} \cap ... \cap P_{i_j}| = C_k^j (k - j)^n \]
    Тогда 
    \[|L| = k^n - \sum_{j=1}^{k} (-1)^{j + 1} C_k^j (k - j)^n = k^n + \sum_{j=1}^{k} (-1)^j C_k^j (k - j)^n = \sum_{j=0}^{k} (-1)^j C_k^j (k - j)^n\]
    Тогда искомая формула чисел Стирлинга:
    \[S(n, k) = \frac{1}{k!}\sum_{j=0}^{k} (-1)^j C_k^j (k - j)^n\] 
\end{proof}


\Section{Теория вероятности}{}{Илья Дудников}
\Subsection{Основы теории вероятности}

\begin{Def}
    $\Omega = \{a_1, a_2, ..., a_n\}$ -- множество всех взаимо-исключающих исходов эксперимента (пространство элементарных событий) \\
    $X \subseteq \Omega$ -- событие
\end{Def}

\begin{Def}
    Дано $\Omega, \mathscr{A} \subset 2^\Omega$. Тогда $\mathscr{A}$ называется алгеброй, если 
    \begin{MyList}
        \item $\Omega \in \mathscr{A}$ 
        \item $A \in \mathscr{A}, B \in \mathscr{A} \SO A \cup B \in \mathscr{A}$
        \item $A \in \mathscr{A} \SO \overline{A} \in \mathscr{A}$  
    \end{MyList}   
\end{Def}

\begin{Prop}
    Если $\mathscr{A}$ -- алгебра, то 
    \begin{MyList}
        \item $\varnothing \in \mathscr{A}$ 
        \item $A, B \in \mathscr{A} \SO A \cap B \in \mathscr{A}$ 
        \item $A, B \in \mathscr{A} \SO A \setminus B \in \mathscr{A}$
        \item $A_i \in \mathscr{A} \SO \bigcup A_i \in \mathscr{A}, \bigcap A_i \in \mathscr{A}$  
    \end{MyList}
\end{Prop}

\begin{proof}
    \begin{MyList}
        \item $\Omega \in \mathscr{A} \SO \overline{\Omega} \in \mathscr{A} \SO \overline{\Omega} = \varnothing \SO \varnothing \in \mathscr{A}$
        \item $\overline{A \cap B} = \overline{A} \cup \overline{B} \in \mathscr{A}$. Тогда $\overline{\overline{A \cap B}} = A \cap B \in \mathscr{A}$
        \item $A \setminus B = A \cap \overline{B} \in \mathscr{A}$ 
        \item Доказывается по индукции.  
    \end{MyList}
\end{proof}

\begin{Def}
    $\mathscr{A}$ называется $\sigma$-алгеброй, если 
    \begin{MyList}
        \item $\Omega \in \mathscr{A}$ 
        \item $A_i \in \mathscr{A}, i = 1, .... \SO \bigcup_{i = 1}^\infty A_i \in \mathscr{A}$
        \item $A \in \mathscr{A} \SO \overline{A} \in \mathscr{A}$
    \end{MyList} 
\end{Def}

\begin{Def}
    Пусть есть пространство $\Omega$, определенная на нём $\mathscr{A}$ -- $\sigma$-алгебра и $f: \mathscr{A} \to \R$ -- функция над множеством.
    Тогда вероятностью называется функция из $\mathscr{A}$ в $\R$ такая, что
    \begin{MyList}
        \item $P(A) \geqslant 0 \ \forall A \in \mathscr{A}$ 
        \item $P(\Omega) = 1$
        \item $A_1, A_2, ... : A_i \cap A_j = \varnothing \ \forall i, j \SO P(\bigcup_{i = 1}^\infty A_i) = \sum_{i=1}^{\infty} P(A_i)$  
    \end{MyList}
    Перечисленные выше свойства называются \textbf{аксиомами теории вероятности}
    
    $(\Omega, \mathscr{A}, P)$ -- вероятностное пространство.
\end{Def}
\Pagebreak

Свойства вероятности:
\begin{MyList}
    \item $P(\Omega) = 1$
    \item $P(\varnothing) = 0$ 
    \item Если $A_1, A_2 \in \mathscr{A}, A_1 \cap A_2 = \varnothing$, то \[P(A_1 \cup A_2) = P(A_1) + P(A_2)\]
    \item Если $A_1, ..., A_n \in \mathscr{A}, A_i \cap A_j = \varnothing \ \forall i, j$, то \[P(\bigcup_{i = 1}^n A_i) = \sum_{i=1}^{n} P(A_i)\]
    \item $P(\overline{A}) = 1 - P(A)$ 
    \begin{proof}
        \[P(\overline{A} \cup A) = P(\Omega) = P(A) + P(\overline{A})\] 
    \end{proof}
    \item Если $A, B \in \mathscr{A}$, то \[P(A \cup B) = P(A) + P(B) - P(A \cap B)\]
    \begin{proof}
        \[A \cup B = (A \setminus B) \cup (B \setminus A) \cup (A \cap B)\]
        
        \[P(A \cup B) = P(A \setminus B) + P(B \setminus A) + P(A \cap B) = P((A \setminus B) \cup (A \cap B)) + P((B \setminus A) \cup (A \cap B)) - P(A \cap B) =\]
        \[= P(A) + P(B) - P(A \cap B)\]
    \end{proof}
    \item $P(\bigcup_{i = 1}^n A_i) = \sum_{i=1}^{n} P(A_i) - \sum_{i, j=1}^{n} (A_i \cap A_j) + ...$
    \item $A_1 \subset A_2 \subset ... \subset A_n \subset ...$
    \[\lim_{n \to \infty} P(A_n) = P(\bigcup_{i = 1}^\infty A_i)\]
    \begin{proof}
        $A_{k - 1} \subset A_k$. Рассмотрим $A_k \setminus A_{k - 1}$. Пусть $A_0 = \varnothing$.
        \[P(\bigcup_{i = 1}^\infty A_i) = \sum_{k=1}^{\infty} P(A_k \setminus A_{k - 1}) = \lim_{n \to \infty} \sum_{k=1}^{n} P(A_k \setminus A_{k - 1}) \lim_{n \to \infty} \sum_{k=1}^{n} P(A_k) - P(A_{k - 1}) =\]
        \[= \lim_{n \to \infty} P(A_n) - P(\varnothing) = \lim_{n \to \infty} P(A_n)\]
    \end{proof} 
    \item $A_1 \supset A_2 \supset ... \supset A_n \supset ...$. Тогда 
    \[\lim_{n \to \infty} P(A_n) = P(\bigcap_{i = 1}^\infty A_i)\]
\end{MyList}

\Pagebreak
\begin{Example}
    Два человека приходят на место в промежуток от 12 до 13ч и ждут 10 минут прежде чем уйти. Найти вероятность того, что они встретятся.
\end{Example}

\begin{Solution}
    Пусть $t_1$ -- время, когда приходит первый, $t_2$ -- время, когда приходит второй.
    \[|t_1 - t_2 \leqslant \frac{1}{6} \EQ \begin{cases}
        t_2 \geqslant t_1 - \frac{1}{6} \\
        t_2 \leqslant t_1 + \frac{1}{6}
    \end{cases}\] 
    \begin{figure*}[ht]
        \centering
        \import{./img}{first_example.pdf_tex}
    \end{figure*}

    Тогда вероятность -- площадь заштрихованной фигуры:
    \[S = 1 - 2 \cdot \frac{\frac{5}{6} \cdot \frac{5}{6}}{2} = 1 - \frac{25}{36} = \frac{11}{36}\]
\end{Solution}

\begin{Example}
    На $[0, 1]$ выбираются два числа $x, y$. Найти вероятность того, что их произведение меньше $\frac{1}{2}$  
\end{Example}

\begin{Solution}
    \[f(x) = \begin{cases}
        1, x \leqslant \frac{1}{2}, \\
        \frac{1}{2x}, x > \frac{1}{2}
    \end{cases}\]
    \begin{figure*}[ht]
        \centering
        \def\svgwidth{.3\columnwidth}
        \import{./img/}{second_example.pdf_tex}
    \end{figure*}

    Тогда искомая вероятность:
    \[P(x \cdot y < \frac{1}{2}) = \int_{0}^{1} f(x)dx = \int_{0}^{\frac{1}{2}} f(x)dx + \int_{\frac{1}{2}}^{1} f(x)dx = \frac{1}{2} + \int_{\frac{1}{2}}^{1} \frac{1}{2x}dx = \frac{1}{2} + \frac{\ln 2}{2}\]
\end{Solution}

\Pagebreak
\Subsection{Условная вероятность}
\begin{Def}
    Вероятность события $A$ при условии, что выполняется событие $B$ равна
    \[P(A | B) = \frac{P(A \cap B)}{P(B)}\] 
\end{Def}

\begin{Example}
    Есть урна, в которой лежит $m$ белых и $n$ черных шаров. Вытащим из неё два шара. Какова вероятность того, что они оба белые?
\end{Example}

\begin{Solution}
    \[P(\text{первый -- белый}) = \frac{m}{m + n}, P(\text{второй -- белый} | \text{первый -- белый}) = \frac{m - 1}{m + n - 1}\]
    \[P(\text{оба белые}) = \frac{m - 1}{m + n - 1} \cdot \frac{m}{m + n}\]
\end{Solution}

Свойства условной вероятности:
\begin{MyList}
    \item $P(\Omega | B) = 1$
    \item $P(\varnothing | B) 0 $ 
    \item $0 \leqslant P(A | B) \leqslant 1$ 
    \item $A \subset C \SO P(A | B) \leqslant P(C | B)$
    \item $P(\overline{A} | B) = 1 - P(A | B)$
    \item $P(A \cup C | B) = P(A | B) + P(C | B) - P(A \cap C | B)$
    \item $P(A \cap B) = P(A | B) \cdot P(B)$
    \[P(A_1 \cap A_2 \cap ... \cap A_n) = P(A_1) \cdot P(A_2 | A_1) \cdot P(A_3 | A_2 \cap A_1) \cdot ... \cdot P(A_n | \bigcap_{i = 1}^{n - 1} A_i)\]
    \[P((A_1 \cap ... \cap A_{n - 1}) \cap A_n) = P(A_n | A_1 \cap ... \cap A_{n - 1}) \cdot P(A_1 \cap ... \cap _{n - 1})\]
\end{MyList}

\begin{Example}
    Бросаем 3 кубика. Найти вероятность того, что хотя бы на одном из них выпадет $1$ при условии, что на всех выпали разные значения.
\end{Example}

\begin{Solution}
    \[P(A | B) = 1 - P(\overline{A} | B) = 1 - \frac{P(\overline{A} \cap B)}{P(B)} = 1 - \frac{1}{2} = \frac{1}{2}\]
\end{Solution}

\Subsection{Независимость событий}
\begin{Def}
    $A$ независимо от $B (P(B) \neq \varnothing)$, если $P(A | B) = P(A)$ 
\end{Def}

\begin{Prop}
    Если $A$ независимо от $B \SO B$ независимо от $A$.   
\end{Prop}

\begin{proof}
    \[P(B | A) = \frac{P(B \cap A)}{P(A)} = \frac{P(A \cap B) \cdot P(B)}{P(A) \cdot P(B)} = P(A | B) \cdot \frac{P(B)}{P(A)} = P(B)\]
\end{proof}

\begin{Def}
    $A, B$ -- независимые, если 
    \[P(A \cap B) = P(A) \cap P(B)\]
\end{Def}

\begin{Def}
    $A_1, ..., A_n$ -- независимы в совокупности, если 
    \[P(\bigcap_{i = 1}^n) = \prod_{i = 1}^n P(A_i)\]
\end{Def}

\begin{Def}
    $A_1, .., A_n$ -- попарно-независимы, если 
    \[\forall i, j \to P(A_i \cap A_j) = P(A_i) \cdot P(A_j)\]
\end{Def}

\begin{Rem}
    Если $A_1, ..., A_n$ попарно-независимы, то они необязательно независимы в совокупности.
\end{Rem}

\Subsection{Формула полной вероятности}

\begin{Def}
    Пусть $H_1, ..., H_n$ -- разбиение $\Omega$. Тогда $H_1 \cup ... \cup H_n = \Omega$ называется полной группой событий.
\end{Def}

\begin{Thm}
    $H_1, ..., H_n$ -- полная группа событий и $P(H_i) > 0 \ \forall i = 1, ..., n$. Тогда 
    \[\forall A \to P(A) = \sum_{i=1}^{n} P(H_i) \cdot P(A | H_i)\] 
\end{Thm}

\begin{proof}
    \[A = A \cap \Omega = A \cap (H_1 \cup ... \cup H_n) = (A \cap H_1) \cup (A \cap H_2) \cup ... \cup (A \cap H_n)\]
    \[P((A \cap H_1) \cup ... \cup (A \cap H_n)) = \sum_{i=1}^{n} P(A \cap H_i) = \sum_{i=1}^{n} P(A | H_i) \cdot P(H_i)\] 
\end{proof}

\begin{Thm}[Формула Байеса]
    Пусть $H_1, H_2, ..., H_n$ -- полная группа событий. $A$ -- событие (считаем произошедшим). Тогда
    \[P(H_k | A) = \frac{P(H_k) \cdot P(A|H_k)}{\sum_{i=1}^{n} P(H_i) \cdot P(A|H_i)}\]
\end{Thm}

\begin{proof}
    \[P(H_k|A) = \frac{P(H_k \cap A)}{P(A)} = \frac{P(H_k) \cdot P(A|H_k)}{\sum_{i=1}^{n} P(H_i) \cdot P(A|H_i)}\] 
\end{proof}

\Subsection{Испытания Бернулли}

\begin{Def}
    Обозначим $P_n(m)$ -- вероятность получить $m$ успехов за $n$ испытаний. 
\end{Def} 

\begin{Thm}[Теорема Бернулли]
    Рассмотрим упорядоченный набор: $\underbrace{SSS...S}_n \underbrace{FFF...F}_{n - m}$, где $S$ обозначает успех, а $F$ -- неудачу.
    В силу независимости испытаний, вероятность получить конкретный упорядоченный набор равна $p^m (1 - p)^{n - m}$. Таких наборов, очевидно, $C_n^m$  
\end{Thm}

\begin{Thm}
    $0 \leqslant m_1 \leqslant m_2 \leqslant n$. $P_n(m_1, m_2)$ -- успех наступил от $m_1$ до $m_2$ раз.
    \[P_n(m_1, m_2) = \sum_{i=m_1}^{m_2} C_n^k p^k (1 - p)^{n - k}\] 
\end{Thm}

\begin{Def}
    Наивероятнейшее число событий -- число событий в испытаниях Бернулли с наибольшей вероятностью.
\end{Def}

\begin{Thm}
    Наивероятнейшее число успехов в $n$ испытаниях заключено между числами $np - (1 - p)$ и $np + p$  
\end{Thm}

\begin{proof}
    Рассмотрим следующее соотношение:
    \[\frac{P_n(m)}{P_n(m - 1)} = \frac{C_n^m p^m (1 - p)^{n - m}}{C_n^{m - 1} p^{m - 1} (1 - p)^{n - m + 1}} = \frac{p}{1 - p} \cdot \frac{n! (m - 1)!(n - m + 1)!}{n!m!(n - m)!} = \frac{p}{1 - p} \cdot \frac{n - m + 1}{m}\]

    Отсюда очевидно, что 
    \begin{gather*}
        P_n(m) > P_n(m - 1), m < (n + 1)p \\
        P_n(m) = P_n(m - 1), m = (n + 1)p \\
        P_n(m) < P_n(m - 1), m > (n + 1)p
    \end{gather*}
    Значит, при $m < (n + 1)p \ P_n(m)$ возрастает, при $m > (n + 1)p$ -- убывает. Тогда несложно найти $m$ такое, чтобы $P_n(m)$ было наибольшим:
    \[\begin{cases}
        P_n(m) > P_n(m - 1) \\
        P_n(m + 1) < P_n(m)
    \end{cases} \EQ \begin{cases}
        m < (n + 1)p \\
        m + 1 > (n + 1)p
    \end{cases} \EQ np + p - 1 < m < np + p\]  
\end{proof}

\Pagebreak
\Subsection{Предельные случаи испытаний Бернулли}

Рассмотрим ситуацию, когда вероятность какого-то события уменьшается пропорционально $n$, т.е. $p \thicksim \frac{1}{n}$ 
\begin{Thm}[Теорема Пуассона]
    Пусть $np \to \lambda$. 
    \[\forall m, \forall \lambda \ \lim_{n \to \infty} P_n(m) = \frac{\lambda^m}{m!}\cdot e^{-\lambda}\]
\end{Thm}

\begin{proof}
    \begin{align*}
        P_n(m) &= C_n^m p^m \cdot (1 - p)^{n - m} = \frac{n!}{m!(n - m)!} \cdot \left(\frac{\lambda}{n}\right)^m \left(1 - \frac{\lambda}{n}\right)^{n - m} = \\
        &= \frac{n(n - 1) ... (n - m) + 1}{m!} \cdot \left(1 - \frac{\lambda}{n}\right)^{n - m} \cdot \left(\frac{\lambda}{n}\right)^m = \\
        &= \frac{\lambda^m}{m!}\left(1 - \frac{\lambda}{n}\right)^n \left(1 - \frac{1}{n}\right) \left(1 - \frac{2}{n}\right)...\left(1 - \frac{m - 1}{n}\right)\left(1 - \frac{\lambda}{n}\right)^{-m} \SO \\
        &\SO \lim_{n \to \infty} P_n(m) = \lim_{n \to \infty} \frac{\lambda^m}{m!} \left(1 - \frac{\lambda}{n}\right)^n = \frac{\lambda^m}{m!}\cdot e^{-\lambda}
    \end{align*}
\end{proof}

\begin{Thm}[Локальная теорема Муавра-Лапласа]
    Пусть $x_n = \frac{m - np}{\sqrt{np(1 - p)}}$. Предположим, что $x_n$ ограничена при $n \to \infty$. Тогда
    \[\sqrt{np(1 - p)} \cdot P_n(m) \thicksim \frac{1}{\sqrt{2\pi}} \cdot e^{-\frac{x_n^2}{2}}\]   
\end{Thm}

\begin{proof}
    Вспомним, что $k! \thicksim \sqrt{2\pi k} \left(\frac{k}{e}\right)^k$. \\
    $n - m = n(1 - p) - x_n\sqrt{np(1 - p)}$. Тогда
    \begin{align*}
        &\sqrt{np(1 - p)}P_n(m) = \sqrt{np(1 - p)} C_n^m p^m (1 - p)^{n - m} = \frac{\sqrt{np(1 - p)} \cdot n!}{m!(n - m)!} \cdot p^m \cdot (1 - p)^{n - m} \\
        &\approx \frac{\sqrt{np(1 - p)} \cdot \sqrt{2\pi n} \left(\frac{n}{e}\right)^n}{\sqrt{2\pi m} \cdot \left(\frac{m}{e}\right)^m \cdot \sqrt{2\pi (n - m)} \cdot \left( \frac{n - m}{e}\right)^{n - m}} \cdot p^m \cdot (1 - p)^{n - m} \\
        &= \frac{\sqrt{np(1 - p)} \cdot \sqrt{n} \cdot n^n}{\sqrt{2\pi} \cdot \sqrt{m} \cdot m^m \cdot (n - m)^{n - m}} \cdot p^m (1 - p)^{n - m} = \frac{1}{\sqrt{2\pi}} \left( \frac{np}{m}\right)^m \cdot \left( \frac{n(1 - p)}{n - m}\right)^{n - m} \sqrt{ \frac{np}{m}} \cdot \sqrt{ \frac{n(1 - p)}{n - m}}\\
    \end{align*} 

    $m = np + x_n\sqrt{np(1 - p)}$
    \begin{align*}
        \frac{m}{np} = 1 + \frac{x_n\sqrt{1 - p}}{\sqrt{np}} &\xrightarrow[n \to \infty]{} 1 \\
        \frac{n - m}{n(1 - p)} = 1 - \frac{x_n\sqrt{p}}{\sqrt{n(1 - p)}} &\xrightarrow[n \to \infty]{} 1
    \end{align*} 

    Пусть, для удобства, $\exp(x) = e^x$. Тогда 
    \begin{gather*}
        \sqrt{np(1 - p)}P_n(m) \approx \frac{1}{\sqrt{2\pi}} \cdot \left(1 + \frac{x_n\sqrt{1 - p}}{\sqrt{np}}\right)^{-m} \left(1 - \frac{x_n\sqrt{p}}{\sqrt{n(1 - p)}}\right)^{-(n - m)} = \\
        = \frac{1}{\sqrt{2\pi}} \exp\left({-m \cdot \ln \left(1 + \frac{x_n\sqrt{1 - p}}{\sqrt{np}}\right) - (n - m) \cdot \ln \left(1 - \frac{x_n\sqrt{p}}{\sqrt{n(1 - p)}}\right)}\right)
    \end{gather*}

    Как мы знаем (откуда?)
    \[\ln(1 + y) \xrightarrow[y \to 0]{}y - \frac{y^2}{2}(1 + O(1))\]
    Следовательно $\sqrt{np(1 - p)}P_n(m) =$ 
    \[
        = \frac{1}{\sqrt{2\pi}} \exp \left(-m \left( \frac{x_n \sqrt{1 - p}}{\sqrt{np}} - \frac{x_n^2}{2np}\right)(1 + O(1)) - (n - m)\left(- \frac{x_n\sqrt{p}}{\sqrt{n(1 - p)}} - \frac{x_n^2p}{2n(1 - p)}\right)(1 + O(1))\right)
    \]
    \begin{gather*}
        x_n \left( \frac{(n - m)\sqrt{p}}{\sqrt{n(1 - p)}} - \frac{m\sqrt{1 - p}}{\sqrt{np}}\right) = \\
        = \frac{x_n}{\sqrt{np(1 - p)}}\left(np(1 - p) - x_n\sqrt{np(1 - p)} p - n(1 - p)\cdot p - x_n\sqrt{np(1 - p)}(1 - p)\right) = \\
        = -x_n^2 (p + (1 - p)) = -x_n^2
    \end{gather*}

    Таким образом:
    \[\sqrt{np(1 - p)}P_n(m) \approx \frac{1}{\sqrt{2\pi}}e^{\left(-x_n^2 + \frac{x_n^2}{2}\right)(1 + O(1))} \approx \frac{1}{\sqrt{2\pi}}e^{- \frac{x_n^2}{2}}\]

\end{proof}

\begin{Thm}[Интегральная теорема Муавра-Лапласа]
  $a_n = \frac{m_1 - np}{\sqrt{npq}}, b_n = \frac{m_2 - np}{\sqrt{npq}}, q = 1 - p$. Пусть $m_1 \to \infty, n \to \infty, a_n, b_n$ -- ограничены. Тогда
  \[\lim_{n \to \infty} \left|P_n(m_1, m_2) - \frac{1}{2\pi} \int_{a_n}^{b_n} e^{- \frac{x^2}{2}} dx\right| = 0\]  
\end{Thm}

\begin{Def}
  $\PHI (x) = \frac{1}{\sqrt{2\pi}} \cdot e^{- \frac{x^2}{2}}$ -- функция Гаусса. \\
  $\Phi(x) = \frac{1}{\sqrt{2\pi}} \cdot \int_{0}^{x} e^{- \frac{z^2}{2}}dz$ -- функция Лапласа. 
\end{Def}

\begin{Cons}
  По локальной теореме Муавра-Лапласа:
  \[P_n(m) \thicksim \frac{\PHI(x)}{\sqrt{npq}}\]
  По интегральной теореме Муавра-Лапласа:
  \[P_n(m_1, m_2) \thicksim \frac{1}{2}(\Phi(b_n) - \Phi(a_n))\]
\end{Cons}

\Subsection{Случайные величины}

Пусть $\Omega = \{\omega_1, \omega_2, ..., \omega_k, ...\}$

\begin{Def}
    Функция, заданная на $\Omega$ -- случайная величина.
    \[x = X(\Omega)\]
\end{Def}

\begin{Def}
    Соответствие, которое каждому $x_i$ сопоставляет вероятность $p_i$ -- распределение (закон распределения) 
\end{Def}

\begin{Rem}
    Если $X$ -- дискретная случайная величина, то $Y = g(X)$ -- тоже дискретная случайная величина и
    \[y_i = g(x_i), p_i = P(X = x_i)\] 
\end{Rem}

\begin{Def}
    Определим случайную величину в более общим случае. Пусть у нас есть $(\Omega, \mathscr{A}, P)$. Тогда случайная величина это
    \[X = X(\omega), \omega \in \Omega : \{X < x\} = \{\omega : X(\omega) < x\} \in \mathscr{A} \ \forall x\]
\end{Def}

\begin{Def}
    $F(x) = P(X < x), x \in (-\infty, +\infty)$ -- функция распределения случайной величины. 
\end{Def}

Свойства:
\begin{MyList}
    \item $F(x_1) \leqslant F(x_2)$ если $x_1 < x_2$
    \item $F(-\infty) = 0, F(+\infty) = 1$
    \item $P(a \leqslant X < b) = F(b) - F(a)$   
\end{MyList}

\begin{Def}
    Пусть $P(y)$ -- неотрицательная функция. Если $F(x) = \int_{-\infty}^{x}f(y)dy$, то $P(y)$ -- плотность распределения.
    В частности, $P(x) = F'(x)$  
\end{Def}

\begin{Def}
    Есть $P(X = x, Y = y) = P(X = x) \cdot P(Y = y)$, где $P(A, B)$ -- вероятность одновременного наступления событий $A$ и $B$, то $X, Y$ -- независимые случайные величины.
\end{Def}

\begin{Def}
    Пусть $X$ -- дискретная случайная величина. Тогда матожиданием называется
    \[\E(X) = \sum_{i=1}^{n} x_i p_i\] 
    а $\E(|X|) = \sum_{i=1}^{n} |x_i| p_i$ -- абсолютный момент. 
\end{Def}

Свойства:
\begin{MyList}
    \item $\E(aX + b) = a\E(x) + b$ 
    \item $\E(X + Y) = \E(X) + \E(Y)$ 
    \item Если $X, Y$ -- независимые случайные величины, то $\E(XY) = \E(X) \cdot \E(Y)$  
\end{MyList}

\Pagebreak
\Subsection{Дисперсия}

\begin{Def}
    $\D(X) = \sum_{i=1}^{n} (X_i - \E(X))^2$ -- дисперсия. 
\end{Def}

\begin{Rem}
    $\D(X) = \E(X - \E(X))^2 p_i$ 
\end{Rem}

Свойства дисперсии:
\begin{MyList}
    \item $\D(X)  = \E(X^2) - (\E(X))^2$ 
    \begin{proof}
        $\D(X) = \sum_{i=1}^{n} (X_i - \E(X))^2 p_i = \sum_{i=1}^{n} X_i^2 p_i - \sum_{i=1}^{n} 2 X_i \E(X) p_i + \sum_{i=1}^{n} (\E(X))^2 p_i = \E(X^2) - 2(\E(X))^2 + (\E(X))^2 \cdot 1 = \E(X^2) - (\E(X))^2$ 
    \end{proof}
    \item $\D(aX + b) = a^2 \cdot \D(X)$
    \item $\D(X + Y) = \D(X) + \D(Y)$ 
    \begin{proof}
        $\D(X + Y) = \E((X + Y)^2) - (\E(X + Y))^2 = \E(X^2) + 2\E(XY) + \E(Y^2) - (\E(X))^2 - 2\E(X)\E(Y) - (\E(Y))^2$.
    \end{proof}
\end{MyList}

\begin{Def}
    $m_k = \E(X^k)$ -- $k$-й момент. \\
    $\E(|X|^k)$ -- $k$-й абсолютный момент. \\
    $M_k = \E(X - \E(X))^k$ -- центральный момент.
\end{Def}

\begin{Def}
    $\cov (X, Y) = \E(X - \E(X))(Y - \E(Y))$ \\
    $\cov (X, Y) = \E(XY) - \E(X) \cdot \E(Y)$  
\end{Def}

\begin{Rem}
    $\cov (X + Z, Y) + \cov(X, Y) + \cov(Z, Y)$ \\
    $\cov (X, Y + Z) = \cov(X, Y) + \cov(X, Z)$ 
\end{Rem}

\begin{Def}
    Коэффициент корелляции случайных величин $X$ и $Y$ 
    \[\rho(X, Y) = \frac{\cov (X, Y)}{\sqrt{\D(X) \cdot \D(Y)}}\]
\end{Def}

Свойства:

\begin{MyList}
    \item $\rho(aX + b, cY + d) = \sign (ac) \rho(X, Y)$ 
\end{MyList}

\Subsection{Производящие функции}
\begin{Def}
    Пусть $X$ -- случайная величина, принимающая значения $Z_+$ с вероятностями $p_0, p_1, ...$ \\
    Рассмотрим функцию $\psi (z) = \sum_{k=1}^{\infty} z^kp_k = \E(z^X), |z| \leqslant 1, z \in \mathbb{C}$. Заметим, что 
    \begin{MyList}
        \item $|\psi(z)| = |\sum_{k=1}^{\infty} z^k p_k| \leqslant \sum_{k=1}^{\infty} |z^k|p_k \leqslant \sum_{k=1}^{\infty} p_k = 1$
        \item $p_n = \frac{1}{n!} \cdot \frac{d^n}{dz^n}\psi(z) |_{z = 0}$
        \item $ \frac{d^n}{dz^n} \psi (z)|_{z = 1} = \E(X(X - 1)...(X - n + 1))$
        \begin{proof}
            $ \frac{d^n}{dz^n} \psi(z) = \sum_{k=n}^{\infty} k(k - 1)...(k - n + 1) \cdot z^{k - n} p_k$ \\
            $\D(X) = \E(X^2) - (\E(X))^2 = \E(X(X - 1)) + \E(X) - (\E(X))^2$. Заметим, что $\E(X) = \psi ' (z), \E(X(X - 1)) = \psi '' (z)$  
        \end{proof}
    \end{MyList}
\end{Def}

\begin{Example}
    $\psi = \frac{1}{4}(1 + z)^2 = \frac{1}{4} + \frac{1}{2}z + \frac{1}{4}z^2$ 
\end{Example}

\Subsection{Характеристические функции}

\begin{Def}
    $\PHI(t) = \E(e^{itX})$. Для дискретной случайной величины:
    \[\PHI(t) = \sum_{k=0}^{\infty} e^{itX}p_k\]
\end{Def}

Свойства:
\begin{MyList}
    \item $\PHI_{aX + b}(t) = e^{itb} \cdot \PHI_X(at)$ 
    \item $\PHI_{X + Y} (t) = \PHI_X (t) \cdot \PHI_Y (t)$
    \item $\E(X^k) = (-i)^k \frac{d^k}{dt^k} \cdot \PHI(t) |_{t = 0}$  
\end{MyList}

\Subsection{Нормальное распределение}

$P(X) = \frac{1}{\sqrt{2\pi \sigma}} \exp \left(- \frac{(X - a)^2}{\sigma^2}\right)$

\begin{Def}
    $N(a, \sigma^2)$ -- нормальное распредение. \\
    $N(0, 1)$ -- стандартное нормальное распределение. 
    \[\PHI(t) = \exp \left(-ita - \frac{\sigma^2 t^2}{2}\right), \E(X) = a, \D(X) = \sigma^2\]
\end{Def}

\begin{Rem}
    $P(|X - a| < 3\sigma) = \Phi(3) \thicksim 0.997$ 
\end{Rem}

\begin{Lm}
    Пусть $X$ -- неотрицательная случайная величина. Тогда
    \[\forall \varepsilon > 0 \ P(X \geqslant \varepsilon) \leqslant \frac{\E(X)}{\varepsilon}\] 
\end{Lm}

\begin{proof}
    $1_{[0, \varepsilon)}(X) + 1_{[\varepsilon, +\infty)}(X) = 1$, где $1_{[a, b)}(x) = \begin{cases}
        1, x \in [a, b) \\
        0, x \notin [a, b)
    \end{cases}$  

    $X \cdot 1_{[\varepsilon, +\infty)} \geqslant \varepsilon \cdot 1_{[\varepsilon, +\infty)}(X)$ 
    \[\E(X \cdot 1_{[\varepsilon, +infty)}(X)) \geqslant \varepsilon \E(1_{[\varepsilon, +\infty)}(X))\]
    \begin{gather*}
        \E(X) = \E(X(1_{[0, \varepsilon)} (X) + 1_{[\varepsilon, +\infty)}(X)) = \E(X \cdot 1_{[0, \varepsilon)}(X)) + \E(X \cdot 1_{[\varepsilon, +\infty)}(X)) \geqslant \\
        \geqslant \E(X \cdot 1_{[\varepsilon, +\infty)}(X)) \geqslant \varepsilon \E(1_{[\varepsilon, +\infty)}(X)) = \varepsilon P(X \geqslant \varepsilon)
    \end{gather*}
\end{proof}

\begin{Thm}[Неравенство Чебышева]
    $\forall Y$ -- случайная величина с конечным вторым моментом. Тогда
    \[\forall \delta \ P(|Y - EY| \geqslant \delta) \leqslant \frac{DY}{\delta^2}\]
\end{Thm}

\begin{proof}
    Рассмотрим $X = |Y - EY|^2, \varepsilon = \delta^2$
    \[P(|Y - EY| \geqslant \delta) = P(|Y - EY|^2 \geqslant \delta^2) \leqslant \frac{\E(Y - EY)^2}{\delta^2} = \frac{DY}{\delta^2}\] 
\end{proof}

\begin{Rem}
    $P(|\sum_{i=0}^{n} K_i - \sum_{i=0}^{n} \E X_i| \geqslant \delta) \leqslant \frac{1}{\delta}\sum_{i=0}^{n} \D X_i$ 
\end{Rem}

\begin{Def}
    Пусть $X_1, X_2, ..., X_n, ...$ -- последовательность случайных величин. \\
    Тогда $X_n \xrightarrow[]{n \to a} X$ если $\E(X_n - X)^2 \to 0$ -- сходимость среднеквадратичная.
\end{Def}

\begin{Def}
    $X_n \xrightarrow[]{P} X$, если $P(|X_n - X| \geqslant \E) \to 0$ -- сходимость по вероятности.
\end{Def}

\begin{Def}
    $X_n \xrightarrow[\text{почти наверное}]{} X$, если $P(\omega : X_n(\omega) \to X(\omega)) = 1$  -- сходимость "почти наверное".
\end{Def}

\begin{Thm}[Закон Больших Чисел]
    $X_1, ... X_n, ...$ -- последовательность одинаково распределенных независимых случайных величин. Пусть $m = EX_i, DX_i < +\infty$.
    Тогда 
    \[\overline{X}_n = \frac{1}{n}\sum_{i=1}^{n} X_i \xrightarrow[n \to \infty]{} m\] 
\end{Thm}

\begin{proof}
    Среднекватратичная сходимость: \\
    $\E \overline{X}_n = \E\left(\frac{1}{n} \sum_{i=1}^{n} X_i\right) = \frac{1}{n} \sum_{i=1}^{n} EX_i = \frac{1}{n} \cdot m \cdot n = m$ \\
    \[\E(\overline{X}_n - m)^2 = \D(\overline{X}_n) = \D\left(\frac{1}{n} \sum_{i=1}^{n} X_i\right) = \frac{1}{n^2}\D(\sum_{i=1}^{n} X_i) = \frac{1}{n^2} \cdot \sum_{i=1}^{n} \D X_i = \frac{1}{n} \cdot \D(X_i) \to 0\]

    Сходимость по вероятности: \\
    \[P(|\overline{X}_n - m)| \geqslant m) = P\left(\left|\sum_{i=1}^{n} X_i - \sum_{i=1}^{n} EX_i\right| \geqslant n \varepsilon\right) \leqslant \frac{\sum_{i=1}^{n} \D X_i}{n^2 \varepsilon^2} = \frac{\D X_i}{n \varepsilon^2} \to 0\]
\end{proof}

\begin{Thm}[Центральная предельная теорема]
    $\{X_i\}$ -- независимые одинаково распределенные случайные величины, $\E X_i = a, \D X_i, \sigma^2$.
    Пусть $S_n = \sum_{i=1}^{n} X_i, F_n(x) = P\left(\frac{S_n - na}{\sigma \sqrt{n}} < x \right), N(X)$ -- стандартное нормальное распределение. Тогда
    \[\sup |F_n(x) - N(X)| \xrightarrow[n \to \infty]{} 0\]   
    т.е. $S_n \to N(na, n \sigma^2)$ 
\end{Thm}

\Section{Ликбез по алгоритмам}{}{Илья Дудников}

\begin{Example}
    $n! = \prod_{i = 1}^n i$ 
\begin{lstlisting}
int res = 1;
for (int i = 1; i <= n; i++, res *= i);
\end{lstlisting}

Либо же можно избрать другой подход:
\begin{lstlisting}
int f(int t) {
    if (n > 0)
        return f(n - 1) * n;
    return 1;
}
\end{lstlisting}

Какой из этих алгоритмов лучше? Очевидно, что оба алгоритма работают за $O(n)$, однако на второй алгоритм требуется больше памяти, а именно $O(n)$ памяти, а первый лишь $O(1)$.
\end{Example}

\Subsection{Полный перебор}

\begin{Example}
    $2x + y = 100, x, y \in \N$. Заметим, что $1 \leqslant x \leqslant 49, 1 \leqslant y \leqslant 99$. Тогда несложно перебрать все варианты: $\forall (a, b) \in X \times Y$ проверяем, выполняется ли $2a + b = 100$.
    Перебор можно было урезать, например, заметив, что $y < 99$, т.к. $x \geqslant 1 \SO 100 - 2x \leqslant 98$. Также, $y \vdots 2$, т.к. $2x \vdots 2, 100 \vdots 2$.
    В конце концов, можно заметить, что $y = 100 - 2x$, значит $\overline{X} = \{1, ..., 99\}, \overline{Y} = \{100 - 2x\}, |X| = 49, |Y| = 1$.
    Значит достаточно перебирать только $b \in X$, что сокращает перебор в 100 раз.
\end{Example}

\begin{Def}
    Будем считать перебор \textbf{оптимальным}, если множество перебираемых значений по мощности асимптотически равно размеру ответа. 
\end{Def}

\begin{Example}
    Решето Эратосфена. Хотим найти все простые числа, меньшие $n$.

\begin{lstlisting}
bool prime[n] = {1};
prime[0] = prime[1] = 0;
for (int i = 2; i * i < n; i++) {
    if (prime[i]) {
        for (int j = i * i; j < n; j += i)
            prime[j] = 0;
    }
}
\end{lstlisting}
\end{Example}

\Subsection{Линейные алгоритмы}

\begin{Example}
    Дана последовательность $\{a_0, ..., a_{n - 1}\}$. Хотим найти $i, j : \sum_{k=i}^{j} a_k$ максимальна.
    
\begin{lstlisting}
int max_sum = 0;
int cur_sum = 0;
for (int i = 0; i < n; i++) {
    cur_sum += a[i];
    max_sum = max(max_sum, cur_sum);
    if (cur_sum < 0)
        cur_sum = 0;
}
\end{lstlisting}
\end{Example}

\Subsection{Разделяй и властвуй}

Идея заключается в разделении задачи на несколько подзадач того же типа и в дальнейшем слиянии получившихся результатов.
\begin{Example}[Сортировка слиянием]
    Имеется массив, который мы хотим отсортировать. Делим массив пополам и рекурсивно выполняем сортировку в левой и правой половинах.
    Слияние половинок выполняется несложно. Массив длиной 1 считаем отсортированным.
    Тогда получается $\log_2 n$ уровней, на каждом из которых выполняется слияние за $O(n)$, тогда общая асимптотика 
    $O(n \log n)$ 
\end{Example}

\begin{Thm}[Мастер теорема]
    Если есть рекуррентное соотношение: 
    \[T(n) = \begin{cases}
        a \cdot T \left(\frac{n}{b}\right) + O(n^c), n > 1 \\
        O(1), n = 1
    \end{cases}\]
    где $n$ -- длина задачи, которая делится на $a$ подзадач длины $\frac{n}{b}$ за время $O(n^c)$ 
    Тогда
    
    \begin{MyList}
        \item Если $c > \log_b a$, то $T(n) = O(n^c)$ 
        \item Если $c = \log_b a$, то $T(n) = O(n^c \cdot \log n)$
        \item Если $c < \log_b a$, то $T(n) = O(n^{\log_b a})$ 
    \end{MyList}
\end{Thm}

\begin{proof}
    Рассмотрим дерево рекурсии:

    \begin{figure}[h]
        \centering
        \begin{subfigure}{.4\textwidth}
            \centering
            \input{img/d_and_c.pdf_tex}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{.59\textwidth}
            \centering
            \begin{tabular}{|c|c|c|c|}
                \hline
                № слоя & \# задач & Размер задач & Накладные расходы \\ \hline
                0 & 1 & $n/b$  & $O(n^c)$  \\ 
                1 & $a$ & $n/b^2$  & $O(n^c)$ \\ 
                ... & $a^i$  & $n/b^i$  & $O \left(a^i \left(\frac{n}{b^i}\right)^c\right) = O\left(m^c \cdot \left(\frac{a}{b^c}\right)^i\right)$  \\
                $\log_b n$  & $a^{\log_b n}$ & $O(1)$ & 1 \\ 
                \hline
            \end{tabular}
        \end{subfigure}
    \end{figure}


    
    Тогда 
    \[T(n) = \sum_{i=0}^{\log_b n} O \left(n^c \cdot \left(\frac{a}{b^c}\right)^i\right) = O\left(n^c \cdot \sum_{i=0}^{\log_b n} \left(\frac{a}{b^c}\right)^i\right)\] 
    \begin{MyList}
        \item $c > \log_b a$, т.е. $\frac{a}{b^c} < 1 \SO \sum_{i=0}^{\log_b n} \left(\frac{a}{b^c}\right)^i$ -- сумма убывающей геометрической прогрессии, т.е. константа. Значит $T(n) = O(n^c)$
        \item $c = \log_b a \SO T(n) = O\left(n^c \sum_{i=0}^{\log_b n} 1\right) = O(n^c \log n)$ 
        \item $c < \log_b a \SO$ 
        \[T(n) = O \left(n^c \sum_{i=0}^{\log_b n} \left(\frac{a}{b^c}\right)^i\right) = O\left(n^c \cdot \left(\frac{a}{b^c}\right)^{\log_b n}\right) = O\left(n^c \cdot \frac{a^{\log_b n}}{b^{\log_b n \cdot c}}\right) = O(a^{\log_b n}) = O(n^{\log_b a})\]
    \end{MyList}
\end{proof}

\begin{Algo}[Алгоритм Карацубы]
    Рассмотрим числа длины $2n$. $A = (A_1 \cdot 10^n + A_2), B = (B_1 \cdot 10^n + B_2)$.
    Тогда $A \cdot B = A_1 B_1 \cdot 10^{2n} + 10^n(A_1 B_2 + A_2 B_1) + A_2 B_2$. Обратимся к мастер теореме.
    $a = 4, b = 2, c = 1$. $\log_b a = \log_2 4 = 2$. Тогда оценка сложности $T(n) = O(n^2)$.
    Рассмотрим следующую величину: $\underbrace{(A_1 + A_2) \cdot (B_1 + B_2)}_\delta = \underbrace{A_1 B_1}_\alpha + \underbrace{A_1 B_2 + A_2 B_1}_\beta + \underbrace{A_2 B_2}_\gamma$. Тогда $a = 3, b = 2, c = 1 \SO T(n) = O(n^{\log_2 3})$         
\end{Algo}

\Subsection{Жадные алгоритмы}

\begin{Example}
    Пусть имеются монетки номиналом в 1, 2, 5, 10, 50, 100. Каким наименьшим количеством монет можно разменять данную сумму?
    \begin{align*}
        x &= \left(\frac{x}{100}\right)k_1 + \underbrace{x \% 100}_{y_1} \\
        y_1 &= \left(\frac{y}{50}\right)k_2 + \underbrace{y_1 \% 50}_{y_2} \\
        ... \\
        y_5 &= \left(\frac{y_4}{1}\right)k_6 + 0 \\
    \end{align*}
\end{Example}

\Subsection{Динамическое программирование}

\begin{Def}
    Динамическое программирование -- способ решений рекуррентных задач с помощью запоминания промежуточных результатов.
\end{Def}

\begin{Example}
    $\PHI_n = \PHI_{n - 1} + \PHI_{n - 2}, \PHI_0 = \PHI_1 = 1$. Если решать эту задачу рекурсивно, несколько значений придётся вычислять несколько раз, что неоптимально.
    Вместо этого можно решать итеративно, запоминая промежуточные результаты:

\begin{lstlisting}
int fib[n];
fib[0] = fib[1] = 1;
for (int i = 2; i < n; i++)
    fib[i] = fib[i - 1] + fib[i - 2]
\end{lstlisting}
\end{Example}

\end{document}