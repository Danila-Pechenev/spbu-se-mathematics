\input{preamble.tex}

\begin{document}
	\Header
	\BeginConspect

	\Section{Системы линейных уравнений}{}{Илья Дудников}

	\[ (*)\begin{cases}
		a_{11} x_1 + a_{12} x_2 + ... + a_{1n} x_n = b_1 \\ 
		a_{21} x_1 + a_{22} x_2 + ... + a_{2n} x_n = b_2 \\ 
		\cdots\\
		a_{m1} x_1 + a_{m2} x_2 + ... + a_{mn} x_n = b_n
	\end{cases}\]
	$A = (a_{ij})$ -- матрица коэффициентов, $X = \begin{pmatrix}
	x_1 \\ 
	x_2 \\ 
	\vdots \\ 
	x_n
	\end{pmatrix}$, $B = \begin{pmatrix}
	b_1 \\ 
	b_2 \\ 
	\vdots \\ 
	b_n
	\end{pmatrix}$.  

	\begin{Def}
		Решение СЛУ $(*)$ называется $\alpha_1, ..., \alpha_n \in K : $ при $x_i = \alpha_i$ все уравнения становятся верными.
	\end{Def}

	\begin{Def}
		СЛУ $(*)$ совместна, если $\exists$ хотя бы одно решение. Иначе - несовместна.
	\end{Def}

	\Subsection{Ранг матрицы}

	$A - m \times n, A = (A_1, A_2, ..., A_m), A_i$ -- строки. \\
	$A = (A^1, A^2, ..., A^n), A^j$ -- столбцы.
	
	\begin{Def}
		Строчным (столбцовым) рангом матрицы $A$ называется максимальное число ЛНЗ строк (столбцов). \\
		Иначе, количество элементов в базисе $\langle A_1, ..., A_m\rangle (\langle A^1, ..., A^n\rangle)$. 
	\end{Def}

	\begin{Thm}
		Строчный и столбцовый ранги совпадают.
	\end{Thm}

	Обозначение: $\rank A$.

	\begin{Def}
		Минором матрицы $A - m \times n$ $k$-го порядка называется определитель, 
		составленный из элементов матрицы $A$, стоящих на $k$ выбранных строках и на $k$ выбранных столбцов.  
	\end{Def}

	\begin{Example}
		$\left(\begin{array}{cccc}
		1 & 4 & 8 & -3 \\ 
		2 & 5 & 9 & -4 \\ 
		3 & 6 & -2 & -5
		\end{array}\right)$. Если вы выберем вторую и третью строку, а также первый и последний столбец, то минор второго порядка:
		\[\left|\begin{array}{cc}
		2 & -4 \\ 
		3 & -5
		\end{array}\right|\]
	\end{Example}

	\begin{Thm}
		Ранг матрицы $A$ равен наибольшему порядку минора, отличного от нуля.
	\end{Thm}

	\begin{Thm}[Связь определителя с рангом матрицы]
		$A - n \times n$. Тогда $\rank A < n \EQ \det A = 0$.
	\end{Thm}

	\begin{proof}
		$\SO$. $\rank A < n \SO$ строки $A_1, ..., A_n$ ЛЗ, т.е.
		$\exists \alpha_1, ..., \alpha_n \in K : \alpha_1 A_1 + \alpha_2 A_2 + ... + \alpha_n A_n = 0$ ( $\alpha_i$ не все равны нулю). 
		Пусть $\alpha_1 \neq 0 \SO A_1 = - \frac{\alpha_2}{\alpha_1} A_2 - ... - \frac{\alpha_n}{\alpha_1} A_n$.
		Обнулим первую строку: прибавим к ней $A_2$, умноженную на $-\frac{\alpha_2}{\alpha_1}$, $A_3$, умноженную на $-\frac{\alpha_3}{\alpha_1}$ и т.д.
		Поскольку теперь первая строка целиком нулевая, то $\det A = 0$. \\

		$\Leftarrow$. Индукция $n = 1 \SO a_{11} = 0$. $n - 1 \to n$.
		\[\left|\begin{array}{cccc}
		a_{11} & a_{12} & \cdots & a_{1n} \\ 
		a_{21} & a_{22} & \cdots & a_{2n} \\ 
		\vdots & \vdots & \ddots & \vdots \\ 
		a_{n1} & a_{n2} & \cdots & a_{nn}
		\end{array}\right| = \]
		Можем считать, что $A^1 \neq 0, a_{11} \neq 0$. Домножим первую строку на $- \frac{a_{21}}{a_{11}}$ и прибавляем ко второй строке.
		Затем домножаем первую строку на $-\frac{a_{31}}{a_{11}}$ и прибавляем ко третьей строке и т.д.  
		\[= \left|\begin{array}{cccc}
		a_{11} & a_{12} & \cdots & a_{1n} \\ 
		0 & a_{22}' & \cdots & a_{2n}' \\ 
		\vdots & \vdots & \ddots & \vdots \\ 
		0 & a_{n2}' & \cdots & a_{nn}'
		\end{array}\right| = a_{11} \cdot \left|\begin{array}{ccc}
		a_{22}' & \cdots & a_{2n}' \\ 
		\vdots & \ddots & \vdots \\ 
		a_{n2}' & \cdots & a_{nn}'
		\end{array}\right|\]
		По предположению $A_2', ..., A_n'$ -- ЛЗ. $\begin{cases}
			A_2' = A_2 - \frac{a_{21}}{a_{11}} \cdot A_1 \\
			\cdots \\
			A_n' = A_n - \frac{a_{n1}}{a_{11}} \cdot A_1
		\end{cases}$. \\  
		$0 = \alpha_2 A_2' + ... + \alpha_n A_n' = (...) A_1 + \alpha_2 \cdot A_2 + ... + \alpha_n A_n \SO A_1, ..., A_n$ -- ЛЗ $\SO \rank A < n$.
	\end{proof}

	\begin{Def}
		Элементарными преобразованиями над строками (столбцами) называется
		\begin{MyList}
			\item Перестановка строк (столбцов).
			\item Умножение строки (столбца) на $\lambda \neq 0$.
			\item Прибавление к одной строке (столбцу) другой строки (столбца), умноженной на $\lambda \neq 0$.
		\end{MyList}
	\end{Def}

	\begin{Thm}
		При элементарных преобразованиях ранг матрицы не меняется.
	\end{Thm}

	\begin{proof}
		$1, 2$ -- очевидно.
		$(A_1, ..., A_i, ..., A_j, ..., A_n) \to (A_1, ..., A_i + \lambda A_j, ..., A_j, ..., A_n)$ 
	\end{proof}

	\begin{Def}
		Матрица называется трапецевидной, если у неё в $\forall$ ненулевой строке число нулей слева различно.
	\end{Def}

	\begin{Rem}
		$\rank$ трапецевидной матрицы равен числу ненулевых строк.
	\end{Rem}

	\begin{Thm}[О вычислении ранга]
		Любую матрицу с помощью элементарных преобразований можно привести к трапецевидной.
	\end{Thm}

	\Subsection{Структура решений СЛУ}

	\begin{Def}
		СЛУ (*) называется однородной, если все свободные члены равны нулю.
	\end{Def}

	\begin{Def}
		Нулевое решение однородной СЛУ называется тривиальным. Любое другое решение -- нетривиальным.
	\end{Def}

	\begin{Lm}
		Пусть $Y, Z$ -- решения $AX = 0 \SO \alpha Y + \beta Z$ -- тоже решение, $\alpha, \beta \in K$.
	\end{Lm}

	\begin{proof}
		\[AY = 0, AZ = 0 \SO A(\alpha Y + \beta Z) = \alpha AY + \beta AZ = 0\]
	\end{proof}

	\begin{Thm}[Структура решений однородной СЛУ]
		$AX = 0, A - m \times n, n$ -- число неизвестных, $r = \rank A \SO$
		$\exists n - r$ ЛНЗ решений $X_1, ..., X_{n - r} : \forall$ решение $X = \alpha_1 X_1 + ... + \alpha_{n - r} X_{n - r}$.  
	\end{Thm}

	\begin{proof}
		$A = (A^1, ..., A^n)$, $A^1, ..., A^r$ -- ЛНЗ столбцы $\SO $
		\[
		\begin{cases}
			A_{r + 1} = \beta_{r + 1 \ 1}A^1 + ... + \beta_{r + 1 \ n} A^{r} \\
			\cdots \\
			A^n = \beta_{n \ 1}A^1 + ... + \beta_{n \ r}A^r
		\end{cases}
		\]
		$AX = 0 \EQ x_1 A^1 + x_2 A^2 + ... + x_n A^n = 0$. \\
		$X_1 = \begin{pmatrix}
		\beta_{r + 1 \ 1} \\ 
		\vdots \\ 
		\beta_{r + 1 \ r} \\ 
		-1 \\ 
		0 \\ 
		\vdots \\ 
		0
		\end{pmatrix}, X_2 = \begin{pmatrix}
		\beta_{r + 2 \ 1} \\ 
		\vdots \\ 
		\beta_{r + 2 \ r} \\ 
		0 \\ 
		-1 \\
		0 \\ 
		\vdots \\ 
		0
		\end{pmatrix}, ..., X_{n + r} = \begin{pmatrix}
		\beta_{n \ 1} \\ 
		\vdots \\ 
		\beta_{n \ r} \\ 
		0 \\ 
		\vdots \\ 
		-1 \\ 
		\end{pmatrix}$ -- решения. \\
		Пусть $Z = \begin{pmatrix}
		x_1^* \\ 
		\vdots \\ 
		x_r^* \\ 
		\vdots \\ 
		x_n^*
		\end{pmatrix}$ -- решение. Рассмотрим $Y = Z + x_{r + 1}^* X_1 + x_{r + 2}^* X_2 + ... + x_n^* X_{n - r}$. 
		$Y = \begin{pmatrix}
		y_1 \\ 
		\vdots \\ 
		y_r \\ 
		0 \\ 
		\vdots \\
		0
		\end{pmatrix}$ -- решение~$\{y_1 A_1 + ... + y_r A_r = 0\}$. Но $A_1, ..., A_r$ -- ЛНЗ $\SO Y = \begin{pmatrix}
		0 \\ 
		\vdots \\ 
		0
		\end{pmatrix} \SO 0 = Z + x_{r + 1}^* X_1 + x_{r + 2}^* X_2 + ... + x_n^* X_{n - r}$.
	\end{proof}

	\begin{Def}
		$\forall n - r$ ЛНЗ решений однородной системы линейных уравнений называется
		\textbf{фундаментальной системой решений},
		решение вида $X = \alpha_1 X_1 + ... + \alpha_{n - r} X_{n - r}$ -- \textbf{общее решение}.
	\end{Def}

	\Subsection{Неоднородные СЛУ}

	$AX = B, A - m \times n, X = \begin{pmatrix}
	x_1 \\ 
	\vdots \\ 
	x_n
	\end{pmatrix}, B = \begin{pmatrix}
	b_1 \\ 
	\vdots \\ 
	b_n
	\end{pmatrix}$. \\
	$\overline{A} = \left(\begin{array}{c|c}
	A & B
	\end{array}\right)$ -- расширенная матрица $m \times (n + 1)$.

	\begin{Thm}[Кронекера-Капелли]
		$(*)$ -- совместна $\EQ \rank A = \rank \overline{A}$. 
	\end{Thm}

	\begin{proof}
		$\SO$. $AX = B$ -- совместна $\SO \exists$ решение $x_1 A^1 + ... + x_n A^n = B \SO$
		$B$ -- линейная комбинация $A^1, ..., A^n \SO \rank A = \rank \overline{A}$.

		$\Leftarrow$. $\rank A = \rank \overline{A} = r \SO \exists A^1, ..., A^r$ -- ЛНЗ $\SO A^1, ..., A^r, B$ -- ЛЗ $\SO B = \alpha_1 A^1 + ... + \alpha_r A^r$, не все $\alpha_i = 0 \SO (\alpha_1, ..., \alpha_r, 0, ..., 0)$ -- решение системы.   
	\end{proof}

	\begin{Thm}[О структуре решений неоднородной СЛУ]
		$AX = B, \rank A = r, n$ -- число неизвестных, система совместна. 
		$X_*$ -- какое-то решение СЛУ, $X_1, ..., X_{n - r}$ -- фундаментальные решения $AX = 0$.
		Тогда любое решение $(*)$ имеет вид $X = \alpha_1 X_1 + ... + \alpha_{n - r} X_{n - r} + X_*, \alpha_1, ..., \alpha_{n - r} \in K$. 
	\end{Thm}

	\begin{proof}
		$AX_* = B \SO AX = AX_* \SO A (X - X_*) = 0 \SO X - X* = \alpha_1 X_1 + ... + \alpha_{n - r} X_{n - r}$.
	\end{proof}

	\begin{Example}[Решение СЛУ методом Гаусса]
		\begin{gather*}
			\begin{cases}
				x_1 + x_2 + x_3 + x_4 = 4 \\
				x_1 + x_2 + 2x_3 + 2x_4 = 2 \\
				2x_1 + 2x_2 + 3x_3 + 3x_4 = 6
			\end{cases} \thicksim \left(\begin{array}{cccc|c}
			1 & 1 & 1 & 1 & 4 \\ 
			1 & 1 & 2 & 2 & 2 \\ 
			2 & 2 & 3 & 3 & 6
			\end{array}\right) \thicksim \\
			\thicksim \left(\begin{array}{cccc|c}
			1 & 1 & 1 & 1 & 4 \\ 
			0 & 0 & 1 & 1 & -2 \\ 
			0 & 0 & 1 & 1 & -2
			\end{array}\right) \thicksim \left(\begin{array}{cccc|c}
			1 & 1 & 1 & 1 & 4 \\ 
			0 & 0 & 1 & 1 & -2 \\ 
			\end{array}\right) \thicksim \left(\begin{array}{cccc|c}
			1 & 1 & 1 & 1 & 4 \\ 
			0 & 1 & 0 & 0 & \alpha \\ 
			0 & 0 & 1 & 1 & -2 \\ 
			0 & 0 & 0 & 1 & \beta
			\end{array}\right) \thicksim \left(\begin{array}{cccc|c}
			1 & 1 & 1 & 0 & 4 - \beta \\ 
			0 & 1 & 0 & 0 & \alpha \\ 
			0 & 0 & 1 & 0 & -2 - \beta \\ 
			0 & 0 & 0 & 1 & \beta
			\end{array}\right) \thicksim \\
			\thicksim \left(\begin{array}{cccc|c}
			1 & 1 & 0 & 0 & 6 \\ 
			0 & 1 & 0 & 0 & \alpha \\ 
			0 & 0 & 1 & 0 & -2 - \beta \\ 
			0 & 0 & 0 & 1 & \beta
			\end{array}\right) \thicksim \left(\begin{array}{cccc|c}
			1 & 0 & 0 & 0 & 6 - \alpha \\ 
			0 & 1 & 0 & 0 & \alpha \\ 
			0 & 0 & 1 & 0 & -2 - \beta \\ 
			0 & 0 & 0 & 1 & \beta
			\end{array}\right) \SO \begin{pmatrix}
				x_1 \\ 
				x_2 \\ 
				x_3 \\ 
				x_4
				\end{pmatrix} = \begin{pmatrix}
				6 \\ 
				0 \\ 
				-2 \\ 
				0
				\end{pmatrix} + \alpha \begin{pmatrix}
				-1 \\ 
				1 \\ 
				0 \\ 
				0
				\end{pmatrix} + \beta \begin{pmatrix}
				0 \\ 
				0 \\ 
				-1 \\ 
				1
				\end{pmatrix}
		\end{gather*}
	\end{Example}

\Section{Линейные отображения векторных пространств}{}{Илья Дудников}

\begin{Def}
	$V, W$ -- векторные пространства над $K$. Отображение $f : V \to W$ называется линейным,
	если:
	\begin{MyList}
		\item $f(x + y) = f(x) + f(y) \ \forall x, y \in V$
		\item $f(\alpha x) = \alpha f(x) \ \forall x \in V, \alpha \in K$ 
	\end{MyList}
\end{Def}

\begin{Rem}
	$1, 2 \thicksim f(\alpha x + \beta y) = \alpha f(x) + \beta f(y) \ \forall x, y \in V, \alpha, \beta \in K$. 
\end{Rem}

\begin{Def}
	$\Hom (V, W) = \{f : V \to W \text{ -- линейные}\}$
\end{Def}

\begin{Lm}
	$\Hom (V, W)$ -- векторное пространство над $K$.
\end{Lm}

\begin{proof}
	$f, g \in \Hom (V, W), (f + g)(x) = f(x) + g(x), (\alpha f)(x) = \alpha f(x) \SO f + g, \alpha f \in \Hom (V, W)$. 
\end{proof}

\begin{Def}
	$f \in \Hom (V, W), \ker f = \{x \in V : f(x) = 0\}$ -- ядро отображения $f$, $\Image f = \{f(x), x \in V\}$ -- образ $f$. 
\end{Def}

\begin{Lm}
	$\ker f \subset V, \Image f \subset W$ -- подпространства. 
\end{Lm}

\begin{proof}
	$x, y \in \ker f, f(x + y) = f(x) + f(y) = 0 + 0 = 0 \SO x + y \in \ker f$.
	Аналогично, $f(\alpha x) = \alpha f(x) = 0 \SO \alpha x \in \ker f \ \forall \alpha \in K \SO \ker f$ -- подпространство.  
\end{proof}

\begin{Ex}
	$\Image f$ -- подпространство. 
\end{Ex}

\begin{Thm}
	$f \in \Hom (V, W)$.
	\begin{MyList}
		\item $f$  -- инъективно $\EQ \ker f = \{0\}$.
		\item $f$ -- сюръективно $\EQ \Image f = W$. 
	\end{MyList} 
\end{Thm} 

\begin{proof}
	$\Leftarrow.$ $x_1 \neq x_2$, если $f(x_1) = f(x_2) \SO f(x_1 - x_2) = 0 \SO x_1 - x_2 \in \ker f \SO x_1~-~x_2~=~0~!? $  \\
	$\SO$. Пусть $x \in \ker f, x \neq 0 \SO f(x) = f(0) = 0 !?$.  
\end{proof}

\Subsection{Матрица линейного отображения}

$e_1, ..., e_n$ -- базис $V, e_1', ..., e_m'$ -- базис $W, f \in \Hom (V, W)$ \\
$x \in V, x = x_1 e_1 + ... + x_n e_n, x_i \in K, f(x) = x_1 f(e_1) + ... + x_n f(e_n) \EQ$ задать $f$ значит задать $f(e_i),~i~=~1, ..., n$. \\

% $f(e_1) = a_{11} e_1' + a_{21} e_2' + ... + a_{m1} e_m'$

\[\begin{cases}
	f(e_1) = a_{11} e_1' + a_{21} e_2' + ... + a_{m1} e_m' \\
	\cdots \\
	f(e_n) = a_{1n} e_1' + a_{2n} e_2' + ... + a_{mn} e_m'
\end{cases}\]

\begin{Def}
	Матрицей $f \in \Hom(V, W)$ в базисе $e_1, ..., e_n$ и $e_1', ..., e_m'$ назыается 
	\[A=\left(\begin{array}{cccc}
	a_{11} & a_{12} & \cdots & a_{1n} \\ 
	\vdots & \vdots & \ddots & \vdots \\ 
	a_{m1} & a_{m2} & \cdots & a_{mn}
	\end{array}\right) = \left(\begin{array}{cccc}
	f(e_1) & f(e_2) & \cdots & f(e_n)
	\end{array}\right)\]
\end{Def}

\begin{Thm}
	\begin{MyList}
		\item $\Hom(V, W)$ взаимно-однозначно соответствует $M(m, n, K)$.
		\item $e_1, ..., e_n$ -- базис $V$, $e_1', ..., e_m'$ -- базис $W$, $x \in V \to X = \begin{pmatrix}
		x_1 \\ 
		\vdots \\ 
		x_n
		\end{pmatrix}, f(x) \in W \to Y = \begin{pmatrix}
		y_1 \\ 
		\vdots \\ 
		y_m
		\end{pmatrix}, f \to A$
		$\SO AX = Y$.  
	\end{MyList}
\end{Thm}

\begin{proof}
	\begin{MyList}
		\item $f \to A$ отображение однозначно определяется $f(e_i) \SO A$ определена однозначно.
		С другой стороны, взяв произвольную матрицу $B$, можем построить по ней отображение $g$.

		\item $f \to A = (a_{ij}), 1 \leqslant i \leqslant n, 1 \leqslant j \leqslant m$.
		\begin{gather*}
			f(x) = f(x_1 e_1 + ... x_n e_n) = x_1 f(e_1) + ... + x_n f(e_n) = \\
			= x_1 (a_{11} e_1' + a_{21} e_2' + ... + a_{m1} e_m') + ... + x_n (a_{1n} e_1' + a_{2n} e_2' + ... + a_{mn} e_m') = \\
			= \underbrace{(a_{11} x_1 + a_{12} x_2 + ... + a_{1n} x_n)}_{y_1} e_1' + ... + \underbrace{(a_{m1} x_1 + a_{m2} x_2 + ... + a_{mn} x_n)}_{y_m} e_m' \SO Y = AX
		\end{gather*}
	\end{MyList}
\end{proof}

\begin{Cons}
	\begin{MyList}
		\item $\dim \Hom(V, W) = \dim V \cdot \dim W$
		\item $\alpha, \beta \in K, f, g \in \Hom(V, W), f \to A, g \to B$ в фиксированных базисах $\SO \alpha f + \beta g \to \alpha A + \beta B$.
		\item $f : V \to W, g : W \to U \SO g \circ f : V \to U, g \circ f(x) = g(f(x))$.
		Фиксируем базисы, $f \to A, g \to B \SO g \circ f \to BA$  
	\end{MyList}
\end{Cons}

\gdef\AuthorName{Дарья Гольденберг}

\begin{proof}
	\begin{MyList}
		\item Соответствие матриц.
		\item $(\alpha f  + \beta g) (e_i) = \alpha f (e_i) + \beta g (e_i) \in \alpha A + \beta B$.
		\item $ V \to n, W \to l, U \to m, A \to l \times n, B \to m\times l\\ g \circ f (e_i) = g (\sum_{k=1}^l a_{ki}e_k) = \sum_{k=1}^n a_{ki} g(e_k') = \sum_{k=1}^l a_{ki} \sum_{j =1}^m b_{jk} e_j'' = \sum_{j = 1}^m \sum_{k = 1}^l b_{jk} a_{ki} e_j''$, где $b_{jk} a_{ki} \to BA$.
	\end{MyList}
\end{proof}

\begin{Thm}
	$f: V \to W, \ \dim V, \dim W < \inf$ 
	$$ \Rightarrow \dim \ker f + \dim \Image f = \dim V$$
\end{Thm}

\begin{proof}
	$\ker f \subset V, e_1,...,e_k$ - базис $\ker f$. Дополним до базиса $V: e_1, ..., e_k, e_{k+1},..., e_n $ -- базис $V$. \\
	$x \in V, f(x)\in \Image f \ f(x) = x_{k+1} f(e_{k+1}) + ... + x_n f(e_n)  \in \Image f \\
	f(e_1) = ... = f(e_k) = 0 \Rightarrow \Image f = \langle f(e_{k+1}), ..., f(e_n) \rangle $. Надо доказать, что $f(e_{k+1}), ..., f(e_n)$ -- ЛНЗ. \\
	Предположим обратное. $\alpha_{k+1} f(e_{k+1}) + ... + \alpha_n  f(e_n) = 0 \Rightarrow f(\alpha_{k+1}e_{k+1} + ... + \alpha_n e_n) = 0 \Rightarrow\alpha_{k+1} e_{k+1} + ... + \alpha_n e_n \in \ker f = \langle e_1, ..., e_k\rangle$ -- невозможно.\\
	$\dim \ker f = k,\dim V = n, \dim \Image f = n - k$.
\end{proof}

\Subsection{Линейные операторы}

\begin{Def}
	Линейным оператором называется линейное отображение $a: V \to V$, т.е. $a \in \Hom(V, V)$. \\
	Обозначается $End V = \Hom(V, V)$.
\end{Def}

\begin{Def}
	Тождественным отображением называется отображение  
\end{Def}

\begin{Def}

\end{Def}

\begin{Example}
	\begin{MyList}
		\item Нулевой оператор. $0 \in End V. \ \ 0(x) = 0$. $0 \to 
			\left(\begin{array}{cccc}
			0 & \cdots & 0 \\ 
			\vdots & \ddots & \vdots \\
			0 &  \cdots & 0
			\end{array}\right) = 0 $
		\item Оператор подобия. $\forall x \in V \ ax = \lambda x \to 
		    \left(\begin{array}{cccc}
			\lambda & \cdots & 0 \\ 
			\vdots & \ddots & \vdots \\
			0 &  \cdots & \lambda
			\end{array}\right) $
		\item Оператор поворота в $\R^2$. $z \to z e^{i\varphi}$ -- поворот на $\varphi$. Зафиксируем базис -- $1, i \Rightarrow a(1) = \cos \varphi + i\sin \varphi, a(i) = i(\cos \varphi + i\sin \varphi) = -\sin \varphi + i\cos \varphi  \ \to$
			$\left(\begin{array}{cccc}
				\cos \varphi & -\sin \varphi \\ 
				\sin \varphi & \cos \varphi
				\end{array}\right) $
		\item Оператор дифференцирования. $V = \R[x]$. $\frac{\,d}{\,dx} f \to f'$, зафиксируем базис -- $1, x, x^2, x^3$. \\ 
		$\frac{\,d}{\,dx}(1) = 0, \frac{\,d}{\,dx} (x) = 1, \frac{\,d}{\,dx}(x^2) = 2x, \frac{\,d}{\,dx} (x^3) = 3x^2$. Тогда матрица имеет вид: 
			$\left(\begin{array}{cccc}
			0 & 1 & 0 & 0\\ 
			0 & 0 & 2 & 0\\
			0 & 0 & 0 & 3 \\
			0 & 0 & 0 & 0
			\end{array}\right)$.\\
		Возьмём другой базис -- $1, x+1, x^2 + x + 1, x^3 + x^2 + x + 1$. \\
		Посчитаем значения: $\frac{\,d}{\,dx} (1) = 0, \frac{\,d}{\,dx}(x + 1) = 1, \frac{\,d}{\,dx}(x^2 + x + 1) = 2x + 1, \frac{\,d}{\,dx}(x^3 +x^2 + x + 1) = 3x^2 + 2x + 1$. \\
		Матрица имеет вид: 
		$\left(\begin{array}{cccc}
			0 & 1 & 1 & 1\\ 
			0 & 0 & 2 & 2\\
			0 & 0 & 0 & 3 \\
			0 & 0 & 0 & 0
			\end{array}\right)$.
	\end{MyList}
\end{Example}

\begin{Def}
	$(e_i), (e_i')$ -- базисы V, $\dim V = n$. Разложим 
	$\begin{cases}
		e_1' = c_{11}e_1 + c_{21}e_2 + ... + c_{n1}e_n \\ 
		\cdots\\
		e_n' = c_{1n}e_1 + c_{2n}e_2 + ... + c_{nn}e_n
	\end{cases}$. Тогда матрица вида $C = 
	\left(\begin{array}{cccc}
		c_{11} & c_{12} & \cdots & c_{1n} \\ 
		c_{21} & c_{22} & \cdots & c_{2n} \\
		\vdots & \ddots & \vdots \\
		c_{n1} & c_{n2} & \cdots & c_{nn}
		\end{array}\right)$ называется матрицой перехода от базиса $(e_i)$ к $(e_i')$.
\end{Def}

\begin{Thm}[Преобразование координат вектора при переходе к другому базису]
	V -- векторное пространство над полем K, $(e_i), (e_i')$ -- базисы V, $x\in V, \ x \to X = 
	\left(\begin{array}{c}
		x_1 \\ 
		x_2 \\ 
		\vdots \\ 
		x_n
		\end{array}\right) $ -- координаты вектора в базисе $(e_i)$. $x \to X' = 
		\left(\begin{array}{c}
		x_1' \\ 
		x_2' \\ 
		\vdots \\ 
		x_n'
		\end{array}\right)$ -- координаты вектора в базисе $(e_i'), C$ -- матрица перехода от $(e_i)$ к $(e_i')$. 
	\begin{MyList}
		\item $X = CX'$
		\item $C - \text{обратима} \ (\det C \neq 0)$		
	\end{MyList}
\end{Thm}

\begin{proof}
	\begin{MyList}
		\item $x = x_1' e_1' + ... + x_n'e_n' = x_1'(c_{11}e_1 + c_{21}e_2 +... + c_{n1}e_n) + ... + x_n'(c_{1n}e_1 + c_{2n}e_2 + ... + c_{nn}e_n) = \underbrace{(c_{11}x_1' + c_{12}x_2' + ... + c_{1n}x_n')}_{x_1} e_1 + ... + \underbrace{(c_{n1}x_1' + c_{n2}x_2' + ... + c_{nn}x_n')}_{x_n} e_n$\\
		$\Rightarrow \left(\begin{array}{c}
			x_1 \\ 
			x_2 \\ 
			\vdots \\ 
			x_n
			\end{array}\right) = C \left(\begin{array}{c}
			x_1' \\ 
			x_2' \\ 
			\vdots \\ 
			x_n'
			\end{array}\right) $
		\item $ \forall X \ X = C X'$ по доказанному, тогда $ X = C X' = C D X \Rightarrow CD = E \Rightarrow \det C \neq 0$.
	\end{MyList}
\end{proof}

\begin{Thm}[Изменение матрицы линейного оператора при переходе к другому базису]
	$V$ -- векторное пространство, $\dim V = n, a \in End V$, фиксируем базисы $(e_i), (e_i'), \ A$ -- матрица оператора в базисе $(e_i), \ A'$ -- в базисе $(e_i')$, C -- матрица перехода от $(e_i) \text{ к } (e_i')$.
	$$\Rightarrow A' = C^{-1} A C$$ 
\end{Thm}

\gdef\AuthorName{Ксения Кузьмина}

\begin{Lm}
	$U \subset V, a \in End \, V\\
	U -$ а-инвариантно $\Leftrightarrow$ $\exists$ базис $V: A = 
	\left(\begin{array}{cc}
		B & C\\
		0 & D
		\end{array}\right), B = \dim U \times \dim U$
\end{Lm}

\begin{proof}
	$U$ -- а-инвариантно. Выберем базис $U$: $e_1, ... , e_k$ и дополним его до базиса $V$ матрицы $a$
	$ae_i = b_{1i}e_1+\dots+b_{ki}e_k \Leftrightarrow \left(\begin{array}{cc}
		b_{1i} & \cdot\\
		b_{ki} & \cdot\\
		0 & \cdot \\
		0 & \cdot
	\end{array}
	\right)$
\end{proof}

\begin{Lm}
	$U, W \subset V, a \in End \, V\\
	V = U \oplus W, U, W$ -- а-инвариантны $\Leftrightarrow \exists$ базис $A = \left(\begin{array}{cc}
		B & 0\\
		0 & C
	\end{array}\right)\\
	B = \dim U \times \dim U, C = \dim W \times \dim W$
\end{Lm}

\begin{proof}
	$V$ = $U \oplus V$, выберем $U: e_1, ..., e_k, W: e_{k+1}, ..., e_n\\
	a(e_i) \in U, i = 1, ..., k, a(e_j) \in W, j = k+1, ..., n \Leftrightarrow A = \left(\begin{array}{cc}
		B & 0\\
		0 & C
	\end{array}\right)$
\end{proof}

\begin{Example}
	\begin{enumerate}
		\item $V = M(2, \R) \ \ a: X \to X^T, X \in M(2, \R)$\\
		$E_{11} = \left(\begin{array}{cc}
			1 & 0\\
			0 & 0
		\end{array}\right), \ \ 
		E_{12} = \left(\begin{array}{cc}
			0 & 1\\
			0 & 0
		\end{array}\right), \ \  
		E_{21} = \left(\begin{array}{cc}
			0 & 0\\
			1 & 0
		\end{array}\right), \ \ 
		E_{22} = \left(\begin{array}{cc}
			0 & 0\\
			0 & 1
		\end{array}\right)\\\\
		a(E_{11}) = E_{11}, \ \ a(E_{12}) = E_{21}, \ \ a(E_{21}) = E_{12} \ \ a(E_{22}) = E_{22}\\\\
		A = \left(\begin{array}{cccc}
			1 & 0 & 0 & 0\\
			0 & 0 & 1 & 0\\
			0 & 1 & 0 & 0\\
			0 & 0 & 0 & 1
		\end{array}\right) \ \ \ \ \  <E_{11}> \oplus <E_{12}, E_{21}> \oplus <E_{22}> \ = V$ инвариантны
		\item $V = K[x]_3 \ \ \ a: \frac{d}{dx} (f \to f') \ \ \ 1, x, x^2, x^3\\
		\left(\begin{array}{cccc}
			0 & 1 & 0 & 0\\
			0 & 0 & 2 & 0\\
			0 & 0 & 0 & 3\\
			0 & 0 & 0 & 1
		\end{array}\right) \ \ \ \frac{d}{dx} : <1, x, x^2> \to <1, x> \subset <1, x, x^2>$
	\end{enumerate}
\end{Example}

\Subsection{Собственные векторы и числа}
\begin{Def} 
	Собственным вектором оператора a называется $\forall$ ненулевой вектор одномерного инвариантного подпространства.
\end{Def} 

\begin{Def} 
	x - собственный вектор, $ax = \lambda x$, тогда $\lambda$ = собственное число, ассоциированное вектору $x$\\
	$a \to A, x \to X \ \ \ AX = \lambda X \Rightarrow (A - \lambda E)X = 0$
\end{Def} 

\begin{Def} 
	Характеристическим многочленом оператора a (матрицы A) назыается $\chi_a(t) = \det (A-tE)$
\end{Def} 

\begin{Thm}[О собственных числах]
	Все собственные числа оператора a и только они являются корнями характеристического многочлена. 
\end{Thm}

\begin{proof}
	$AX = \lambda X \Leftrightarrow (A - \lambda E)X = 0$ -- имеет ненулевое решение $\Leftrightarrow 
	\det (A- \lambda E)X = 0 \Leftrightarrow$ все собственные числа корни $\chi_a(t)$
\end{proof}

\begin{Lm}[Независимость собственных чисел от выбора базиса]
	Характеристические многочлены оператора a в разных базисах совпадают. 
\end{Lm}

\begin{proof}
	$a(e_i) \to A \ \ \ (e_i') \to A' \ \ \ C $ -- матрица перехода от $(e_i)$ к $(e_i')\\
	A' = C^{-1}AC \ \ \chi_a(t) = \det (A' - tE) = \det(C^{-1}AC) = \det (C^{-1}AC - t \cdot C^{-1}C) =
	\det(C^{-1} (A-tE)C) = \det C^{-1} \cdot \det(A - tE) \cdot \det C = \det(A-tE) = \chi_a(t)e_i$
\end{proof}

\begin{Thm}[Линейная независимость собственных векторов]
	Собственные векторы, соответствующие различным собственным числам, линейно независимы. 
\end{Thm} 

\begin{proof}
	$n = 1$ -- очевидно.
	Пусть доказали при $n-1$. Индукционный переход: $n-1 \to n: V_1, V_2, ..., V_n$ -- собственные векторы\\
	$aV_i = \lambda_i V_i, \ \ \ \lambda_1, ..., \lambda_n$ -- различны\\
	Пусть $V_1, V_2, ..., V_n$ -- линейно зависимы. Тогда $\alpha_1 V_1 + \alpha_2 V_2 + ... + \alpha_n V_n = 0, \alpha_i \in K \Rightarrow$
	под действием a: $\alpha_1 \lambda_1 V_1 + \alpha_2 \lambda_2 V_2 + ... + \alpha_n \lambda_n V_n = 0$\\
	Будем считать, что $\lambda_1 \neq 0 \Rightarrow \alpha_1 \lambda_1 V_1 + \alpha_2 \lambda_2 V_2 + ... + \alpha_n \lambda_n V_n - \lambda_1(\alpha_1 V_1 + ... + \alpha_n V_n) =
	\alpha_2(\lambda_2 - \lambda-1)V_2 + ... + \alpha_n(\lambda_n - \lambda_1)V_n = 0 \Rightarrow$ по предположению индукции $\alpha_2 = ... = \alpha_n = 0$ 
\end{proof}

\begin{Def} 
	Оператор a называется диагонализируемым, если существует базис такой, что $A = \left(\begin{array}{cccc}
		\lambda_1 & 0 & 0 & 0\\
		0 & \lambda_2 & 0 & 0\\
		0 & 0 & \ddots & 0\\
		0 & 0 & 0 & \lambda_n
	\end{array}
	\right)$
\end{Def} 

\begin{Thm}[Критерий диагонализируемости] 
	Если $\chi_a(t)$ имеет $n$ различных корней $(n = \dim V)$ над рассматриваемым полем, то оператор a -- диагонализируем. 
\end{Thm} 

\begin{proof}
	В качестве базиса берём собственные векторы. 
\end{proof}

\begin{Example}
	Оператор поворота $A = \left(\begin{array}{cc}
		\cos \varphi & - \sin \varphi\\
		\sin \varphi & \cos \varphi
	\end{array}\right)$ -- недиагонализируем над $\R$
\end{Example}

\begin{Lm}
	Над полем $\C$ любой оператор имеет одномерное инвариантное подпространство.
\end{Lm}

\begin{Def} 
	Кратность $\lambda$ как кратность корня $\chi_a (t) = 0$ называется алгебраической кратностью собственного числа. 
\end{Def} 

\begin{Def}
	$\lambda$ -- собственное число, $V^{\lambda} = \{x \in V: ax = \lambda x\}$\\
	$\dim V^{\lambda}$ -- геометрическая кратность собственного числа $\lambda$
\end{Def}

\begin{Example}
	$A = \left(\begin{array}{cc}
		\lambda & 0\\
		0 & \lambda\\
	\end{array}
	\right) \ \ \chi_a(t) = \left|\begin{array}{cc}
		\lambda - t & 0\\
		0 & \lambda -t
	\end{array}\right| = (A-tE) = (\lambda - t)^2 \Rightarrow \lambda$ собственное число алгебраической кратности 2.\\
	$(A - \lambda E)X = 0$\\
	$\left( \left(\begin{array}{cc}
		\lambda & 0\\
		0 & \lambda
	\end{array}\right) - \lambda \left(\begin{array}{cc}
		1 & 0\\
		0 & 1
	\end{array}\right)\right) \left( \begin{array}{c}
		X_1\\
		X_2
	\end{array}\right) = \left( \begin{array}{c}
		0\\
		0
	\end{array} \right)\\
	\dim V^{\lambda} = 2$ -- геометрическая кратность
\end{Example}

\begin{Example}
	$A = \left(\begin{array}{cc}
		\lambda & 1\\
		0 & \lambda
	\end{array} \right)$
	
	$\chi_a(t) = \left|\begin{array}{cc}
	\lambda - t & 1\\
	0 & \lambda - t
	\end{array} \right| = (\lambda - t)^2 \Rightarrow$ алгебраическая кратность $\lambda$ = 2

	$\left( \left(\begin{array}{cc}
		\lambda & 1
		\\
		0 & \lambda
	\end{array}\right) - \lambda \left(\begin{array}{cc}
		1 & 0\\
		0 & 1
	\end{array}\right)\right) \left( \begin{array}{c}
		X_1\\
		X_2
	\end{array}\right) = \left( \begin{array}{c}
		0\\
		0
	\end{array} \right)$\\

	$\left(\begin{array}{cc}
		0 & 1\\
		0 & 0
	\end{array}\right)
	\left(\begin{array}{c}
		X_1\\
		X_2
	\end{array}\right)
	\left(\begin{array}{c}
		0\\
		0
	\end{array}\right) \ \ \ V^{\lambda} = <\left(\begin{array}{c}
		1\\
		0
	\end{array}\right)> \\ \dim V^{\lambda} = 1$ -- геометрическая кратность
\end{Example}

\begin{Lm}
	Геометрическая кратность собственного числа $\lambda \leqslant$ алгебраической кратности
\end{Lm}

\begin{proof}
	$V^{\lambda}$ -- инвариантно относительно a, $V^{\lambda} = \{x: ax = \lambda x\}$\\
	По лемме: $a \to \left(\begin{array}{cc}
		B & C\\
		0 & D
	\end{array}\right) \ \ \ B - m \times m, \dim V^{\lambda} = m\\
	a \big|_{V^{\lambda}} = \chi_a \big|_V^{\lambda} = (t - \lambda)^m\\
	\chi_a = \det \left( \left(\begin{array}{cc}
		B & C\\
		0 & d
	\end{array}\right) - tE \right) = (t - \lambda)^m p(t) \Rightarrow$ алгебраическая кратность $\lambda \geqslant m$ 
\end{proof}

\begin{Thm}[Критерий диагонализируемости] 
	$a \in End \, V$ -- диагонализируема $\Leftrightarrow$ 1. Все собственные числа $\in K$ 2. $\forall$ собственных чисел $\lambda$ алгебраическая кратность = геометрическая кратность 
\end{Thm} 

\Subsection{Жорданова нормальная форма}
\begin{Def} 
	Жордановой клеткой порядка m соответствующей собственному числу $\lambda$ называется\\
	$J_m(\lambda) = \left( \begin{array}{cccc}
		\lambda & 1 & \cdots & 0\\
		\vdots & \lambda &  & \vdots\\
		0 & & \ddots &  1\\
		0 & \dots & & \lambda
	\end{array} \right)$
\end{Def} 

\begin{Example}
	\begin{enumerate}
		\item $\left(\begin{array}{cc}
			\lambda & 1\\
			0 & \lambda
		\end{array}\right)$
		\item $\left(\begin{array}{ccc}
			\lambda & 1 & 0\\
			0 & \lambda & 1\\
			0 & 0 & \lambda
		\end{array}\right)$
	\end{enumerate}
\end{Example}

\begin{Def} 
	ЖНФ оператора $a \in End V$ называется $$\left(\begin{array}{cccc}
		J_{k_1}()\lambda_1) &  &  & \\
		 & J_{k_2}()\lambda_2) &  &\\
		 & & \ddots &\\
		 & & & J_{k_n}()\lambda_n)
	\end{array}\right)$$
\end{Def} 

\begin{Def} 
	Базис, в котором оператор a имеет ЖНФ называется жордановом
\end{Def} 

\begin{Thm}[ЖНФ] 
	\begin{enumerate}
		\item Над алгебраическим замкнутым полем $\forall a \in End V$ имеет ЖНФ
		\item ЖНФ определена с точностью до перестановки клеток
	\end{enumerate}
\end{Thm} 

\begin{Thm} 
	$a \in End V$ имеет ЖНФ над произвольным полем $\Leftrightarrow$ характеристический многочлен раскладывается на линейные множители
\end{Thm} 
\end{document}